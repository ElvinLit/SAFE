{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ea0899-2874-4ff9-9f00-bfe8b19fca4f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9a37aa6-e3d7-44c3-8510-20c402764c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "695de822-452d-4201-af27-0c377d4cf604",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf8e9a68-a3ca-4ca0-ac15-52f73656fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('data/x_train.npy')\n",
    "y_train = np.load('data/y_train.npy')\n",
    "\n",
    "X_test = np.load('data/x_test.npy')\n",
    "y_test = np.load('data/y_test.npy')\n",
    "\n",
    "X_val = np.load('data/x_val.npy')\n",
    "y_val = np.load('data/y_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a6113e-db92-4fb3-b351-fa7cc3bed824",
   "metadata": {},
   "source": [
    "# PCA Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b614cd2-1472-4c48-926c-fff6f83a5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca_feature_selection(X, k, explained_variance_threshold=0.95):\n",
    "\n",
    "    pca = PCA()\n",
    "    pca.fit(X)\n",
    "    cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "    n_components = np.argmax(cumulative_variance >= explained_variance_threshold) + 1\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X)\n",
    "\n",
    "    feature_importance = np.abs(pca.components_).sum(axis=0)\n",
    "    top_k_indices = np.argsort(feature_importance)[-k:]\n",
    "    \n",
    "    return top_k_indices\n",
    "\n",
    "k = 31\n",
    "top_k_features = pca_feature_selection(X_train, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52e7564e-8523-4262-94bb-edf156e5a36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  5,  7,  8,  9, 10, 11, 18, 23, 24, 25, 26, 27, 28, 30, 32,\n",
       "       33, 34, 35, 42, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features_indices = top_k_features\n",
    "np.sort(top_features_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e655460-d4ce-4ec0-8a9f-ecb1e5570257",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.where(y_train == 11, 0, 1)\n",
    "y_test = np.where(y_test == 11, 0, 1)\n",
    "y_val = np.where(y_val == 11, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5a5a9b4-dc85-4547-94c6-4f617fc92b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = X_train[:, top_features_indices]\n",
    "X_test_selected = X_test[:, top_features_indices]\n",
    "X_val_selected = X_val[:, top_features_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0508401d-a76e-419b-bef4-be7c204f2b53",
   "metadata": {},
   "source": [
    "# PyDeepInsight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fdd1d8d-faeb-496d-9f8c-9c043ec5cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDeepInsight import ImageTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f30af3f2-0e04-4b2f-a2eb-96d262846b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = ImageTransformer(\n",
    "    pixels=8,\n",
    "    feature_extractor='tsne',\n",
    "    discretization='lsa'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cfe54ce-0775-4491-a80c-feb99153a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "it.fit(X_train_selected)\n",
    "X_train_images = it.transform(X_train_selected, 'pytorch')\n",
    "\n",
    "X_test_images = it.transform(X_test_selected, 'pytorch')\n",
    "\n",
    "X_val_images = it.transform(X_val_selected, 'pytorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e2cb7-61f4-4b11-8b1d-9c9345327caa",
   "metadata": {},
   "source": [
    "# MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d921a69-f2a9-46ca-84c4-b3a9587864ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples, channels, img_height, img_width = X_train_images.shape\n",
    "latent_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93d47b2c-847b-458f-b914-5ee0e30c5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, img_channels=1, feature_dim=32, latent_dim=2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(img_channels, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(32 * 2 * 2, feature_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))  # Output: (batch_size, 16, 8, 8)\n",
    "        x = self.pool(x)              # Output: (batch_size, 16, 4, 4)\n",
    "        x = self.relu(self.conv2(x))  # Output: (batch_size, 32, 4, 4)\n",
    "        x = self.pool(x)              # Output: (batch_size, 32, 2, 2)\n",
    "        x = x.view(x.size(0), -1)     # Flatten to (batch_size, 128)\n",
    "        x = self.fc1(x)               # Output: (batch_size, feature_dim)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04caf141-2602-4a0e-86a7-1064e127a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, img_channels=1, feature_dim=32):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc2 = nn.Linear(feature_dim, 32 * 2 * 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(16, img_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.relu(self.fc2(z))           # Output: (batch_size, 128)\n",
    "        x = x.view(x.size(0), 32, 2, 2)      # Reshape to (batch_size, 32, 2, 2)\n",
    "        x = self.upsample(x)                 # Upsample to (batch_size, 32, 4, 4)\n",
    "        x = self.relu(self.deconv1(x))       # Output: (batch_size, 16, 4, 4)\n",
    "        x = self.upsample(x)                 # Upsample to (batch_size, 16, 8, 8)\n",
    "        x = self.sigmoid(self.deconv2(x))    # Output: (batch_size, img_channels, 8, 8)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dc81be8-c7c6-4ee9-a28a-125ae58c172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAE(nn.Module):\n",
    "    def __init__(self, img_channels=1, feature_dim=32, latent_dim=2):\n",
    "        super(MAE, self).__init__()\n",
    "        self.encoder = Encoder(img_channels, feature_dim, latent_dim)\n",
    "        self.decoder = Decoder(img_channels, feature_dim)\n",
    "\n",
    "    def mask_input(self, x, mask_ratio=0.25):\n",
    "        # Generate a mask with 0s and 1s, keeping only (1-mask_ratio) of the original input\n",
    "        mask = torch.rand(x.shape, device=x.device) > mask_ratio\n",
    "        x_masked = x * mask\n",
    "        return x_masked, mask\n",
    "\n",
    "    def forward(self, x, mask_ratio=0.25):\n",
    "        x_masked, mask = self.mask_input(x, mask_ratio)  # Apply masking to input\n",
    "        z = self.encoder(x_masked)\n",
    "        reconstructed = self.decoder(z)\n",
    "        return reconstructed, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42c77a18-9e8f-4403-9a61-4a62dca55b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_loss_function(reconstructed, original, mask):\n",
    "    # Only calculate reconstruction loss on the masked parts\n",
    "    masked_original = original * mask\n",
    "    reconstruction_loss = F.mse_loss(reconstructed, masked_original, reduction='sum')\n",
    "    return reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae30c592-8fc1-4bed-9fef-83d42fad2468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MAE(img_channels=3, feature_dim=32, latent_dim=16).to(device)\n",
    "model.load_state_dict(torch.load(\"deepinsight_mae_normal_norf.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7643352c-a46e-4545-ba7a-6f9ac0a73666",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4692a90-e22d-454c-997c-b393d6e1d901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_248/2967385897.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train_normal, dtype=torch.float32)\n",
      "/tmp/ipykernel_248/2967385897.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_248/2967385897.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_tensor = torch.tensor(X_val_images, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "normal_indices = np.where(y_train == 0)[0]\n",
    "X_train_normal = X_train_images[normal_indices]\n",
    "y_train_normal = y_train[normal_indices]\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_normal, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_images, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_images, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, torch.tensor(y_test, dtype=torch.long))\n",
    "val_dataset = TensorDataset(X_val_tensor, torch.tensor(y_val, dtype=torch.long))\n",
    "\n",
    "batch_size = 32 \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acfc7fe2-0a19-4882-a84e-d6e68ad7b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_latent_features(model, data_loader, device='cuda'):\n",
    "    model.eval() \n",
    "    latent_features = []  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, total=len(data_loader), desc=\"Extracting features\"):\n",
    "            if len(batch) == 2:\n",
    "                data, _ = batch  \n",
    "            else:\n",
    "                (data,) = batch  \n",
    "            \n",
    "            data = data.to(device)\n",
    "\n",
    "            latent_feature = model.encoder(data)\n",
    "            latent_features.append(latent_feature.cpu().numpy())\n",
    "\n",
    "    latent_features = np.concatenate(latent_features, axis=0)\n",
    "    \n",
    "    return latent_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0d8ae98-d2c0-4932-b250-14c1d7433876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 8124/8124 [00:02<00:00, 3442.80it/s]\n",
      "Extracting features: 100%|██████████| 3506/3506 [00:01<00:00, 3296.42it/s]\n",
      "Extracting features: 100%|██████████| 4383/4383 [00:01<00:00, 3293.03it/s]\n"
     ]
    }
   ],
   "source": [
    "train_latent_features = extract_latent_features(model, train_loader, device)\n",
    "val_latent_features = extract_latent_features(model, val_loader, device)\n",
    "test_latent_features = extract_latent_features(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d49fafa-2efe-4166-8f38-79e3b42e0a01",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SGDOCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ec4ea3d8-2406-4307-ba39-6a3392b3c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDOneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8f761e90-8a6d-4a85-a220-605a5f077a22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-14 19:59:45,337] A new study created in memory with name: no-name-8f8b35f0-2553-45cd-9f40-187a3c10c540\n",
      "[I 2024-10-14 19:59:45,561] Trial 0 finished with value: 0.7181600977584854 and parameters: {'nu': 0.20254735531844803, 'learning_rate': 'constant', 'eta0': 0.15083274778221079, 'power_t': 0.32484394722973065}. Best is trial 0 with value: 0.7181600977584854.\n",
      "[I 2024-10-14 19:59:45,782] Trial 1 finished with value: 0.7701671617450055 and parameters: {'nu': 0.21765733048784877, 'learning_rate': 'optimal', 'eta0': 0.25538704995273703, 'power_t': 0.04725850038947854}. Best is trial 1 with value: 0.7701671617450055.\n",
      "[I 2024-10-14 19:59:45,981] Trial 2 finished with value: 0.7681730431100681 and parameters: {'nu': 0.13578044325288144, 'learning_rate': 'optimal', 'eta0': 0.23282069303432762, 'power_t': -1.1468497474537926}. Best is trial 1 with value: 0.7701671617450055.\n",
      "[I 2024-10-14 19:59:46,256] Trial 3 finished with value: 0.733638831402693 and parameters: {'nu': 0.44895790360901955, 'learning_rate': 'invscaling', 'eta0': 0.30808657616032553, 'power_t': -1.8360542180890986}. Best is trial 1 with value: 0.7701671617450055.\n",
      "[I 2024-10-14 19:59:46,530] Trial 4 finished with value: 0.733638831402693 and parameters: {'nu': 0.2248219679235565, 'learning_rate': 'invscaling', 'eta0': 0.3896774770006897, 'power_t': -0.9597783276773821}. Best is trial 1 with value: 0.7701671617450055.\n",
      "[I 2024-10-14 19:59:46,741] Trial 5 finished with value: 0.7499982654668322 and parameters: {'nu': 0.0665733619626567, 'learning_rate': 'optimal', 'eta0': 0.11439135802687275, 'power_t': -1.8695006030649686}. Best is trial 1 with value: 0.7701671617450055.\n",
      "[I 2024-10-14 19:59:51,416] Trial 6 finished with value: 0.76838851971078 and parameters: {'nu': 0.1468121092934706, 'learning_rate': 'adaptive', 'eta0': 0.11066572284371172, 'power_t': 2.7211226959941417}. Best is trial 1 with value: 0.7701671617450055.\n",
      "[I 2024-10-14 19:59:51,625] Trial 7 finished with value: 0.7696714772644861 and parameters: {'nu': 0.19319558918682522, 'learning_rate': 'optimal', 'eta0': 0.3464308943450463, 'power_t': -1.5621859382818306}. Best is trial 1 with value: 0.7701671617450055.\n",
      "[I 2024-10-14 19:59:51,862] Trial 8 finished with value: 0.733638831402693 and parameters: {'nu': 0.46645189705518547, 'learning_rate': 'invscaling', 'eta0': 0.04810355984442553, 'power_t': 2.7974822718526733}. Best is trial 1 with value: 0.7701671617450055.\n",
      "[I 2024-10-14 19:59:55,175] Trial 9 finished with value: 0.6311073576666392 and parameters: {'nu': 0.48417002065179576, 'learning_rate': 'adaptive', 'eta0': 0.32263573642014487, 'power_t': 1.8335867460377466}. Best is trial 1 with value: 0.7701671617450055.\n",
      "[I 2024-10-14 19:59:55,449] Trial 10 finished with value: 0.739619251832749 and parameters: {'nu': 0.35108863906971716, 'learning_rate': 'constant', 'eta0': 0.4942544198466755, 'power_t': -2.921774843164996}. Best is trial 1 with value: 0.7701671617450055.\n",
      "[I 2024-10-14 19:59:55,675] Trial 11 finished with value: 0.7700930719648362 and parameters: {'nu': 0.2964670310398236, 'learning_rate': 'optimal', 'eta0': 0.24252584859834314, 'power_t': 0.39775848312683276}. Best is trial 1 with value: 0.7701671617450055.\n",
      "[I 2024-10-14 19:59:55,897] Trial 12 finished with value: 0.7693890541960888 and parameters: {'nu': 0.3204744696286219, 'learning_rate': 'optimal', 'eta0': 0.21774965866098087, 'power_t': 0.5567940306420366}. Best is trial 1 with value: 0.7701671617450055.\n",
      "[I 2024-10-14 19:59:56,137] Trial 13 finished with value: 0.7696857670979668 and parameters: {'nu': 0.31729106284906133, 'learning_rate': 'optimal', 'eta0': 0.19482001131387952, 'power_t': 1.1297221920592992}. Best is trial 1 with value: 0.7701671617450055.\n",
      "[I 2024-10-14 19:59:56,375] Trial 14 finished with value: 0.7458114126605141 and parameters: {'nu': 0.010889847817772802, 'learning_rate': 'optimal', 'eta0': 0.2805790259699594, 'power_t': -0.3949562918872181}. Best is trial 1 with value: 0.7701671617450055.\n",
      "[I 2024-10-14 19:59:56,613] Trial 15 finished with value: 0.7701805834233678 and parameters: {'nu': 0.2746666295558746, 'learning_rate': 'optimal', 'eta0': 0.4159901546666155, 'power_t': 1.236265732692447}. Best is trial 15 with value: 0.7701805834233678.\n",
      "[I 2024-10-14 19:59:56,854] Trial 16 finished with value: 0.7738763833471355 and parameters: {'nu': 0.3938043203688872, 'learning_rate': 'optimal', 'eta0': 0.45209970026442103, 'power_t': 1.5606992514854696}. Best is trial 16 with value: 0.7738763833471355.\n",
      "[I 2024-10-14 19:59:57,164] Trial 17 finished with value: 0.76428838789554 and parameters: {'nu': 0.39306728810786123, 'learning_rate': 'constant', 'eta0': 0.47875937187556084, 'power_t': 1.6768267320953651}. Best is trial 16 with value: 0.7738763833471355.\n",
      "[I 2024-10-14 19:59:59,922] Trial 18 finished with value: 0.5806451612903226 and parameters: {'nu': 0.3991634033904572, 'learning_rate': 'adaptive', 'eta0': 0.42206507734987303, 'power_t': 2.0699881010696934}. Best is trial 16 with value: 0.7738763833471355.\n",
      "[I 2024-10-14 20:00:00,146] Trial 19 finished with value: 0.7700076443608138 and parameters: {'nu': 0.2681747636395435, 'learning_rate': 'optimal', 'eta0': 0.42753457671233575, 'power_t': 1.2574006594077083}. Best is trial 16 with value: 0.7738763833471355.\n",
      "[I 2024-10-14 20:00:00,379] Trial 20 finished with value: 0.7790801153088467 and parameters: {'nu': 0.4072055263229023, 'learning_rate': 'optimal', 'eta0': 0.37819383999012735, 'power_t': 1.1600041171517756}. Best is trial 20 with value: 0.7790801153088467.\n",
      "[I 2024-10-14 20:00:00,595] Trial 21 finished with value: 0.7754479948692798 and parameters: {'nu': 0.40147758617457774, 'learning_rate': 'optimal', 'eta0': 0.39813003746070963, 'power_t': 1.1288243447426047}. Best is trial 20 with value: 0.7790801153088467.\n",
      "[I 2024-10-14 20:00:00,816] Trial 22 finished with value: 0.7802401372212693 and parameters: {'nu': 0.41165259528202464, 'learning_rate': 'optimal', 'eta0': 0.3642152895458759, 'power_t': 2.2142574240601216}. Best is trial 22 with value: 0.7802401372212693.\n",
      "[I 2024-10-14 20:00:01,039] Trial 23 finished with value: 0.7830868236342134 and parameters: {'nu': 0.4319451569265967, 'learning_rate': 'optimal', 'eta0': 0.36865337405127446, 'power_t': 2.2988949628851127}. Best is trial 23 with value: 0.7830868236342134.\n",
      "[I 2024-10-14 20:00:01,272] Trial 24 finished with value: 0.770400962666944 and parameters: {'nu': 0.35114933117917546, 'learning_rate': 'optimal', 'eta0': 0.35164675155522246, 'power_t': 2.28506883250538}. Best is trial 23 with value: 0.7830868236342134.\n",
      "[I 2024-10-14 20:00:01,512] Trial 25 finished with value: 0.7839603929949722 and parameters: {'nu': 0.4430381929494342, 'learning_rate': 'optimal', 'eta0': 0.36733623944233057, 'power_t': 2.4272753038834587}. Best is trial 25 with value: 0.7839603929949722.\n",
      "[I 2024-10-14 20:00:01,863] Trial 26 finished with value: 0.4945594680368747 and parameters: {'nu': 0.4473741805829723, 'learning_rate': 'constant', 'eta0': 0.28680615259456627, 'power_t': 2.9823386982341367}. Best is trial 25 with value: 0.7839603929949722.\n",
      "[I 2024-10-14 20:00:05,404] Trial 27 finished with value: 0.6501778756564459 and parameters: {'nu': 0.4363803317750961, 'learning_rate': 'adaptive', 'eta0': 0.3499761407474668, 'power_t': 2.4844939390742056}. Best is trial 25 with value: 0.7839603929949722.\n",
      "[I 2024-10-14 20:00:05,661] Trial 28 finished with value: 0.733638831402693 and parameters: {'nu': 0.48525037523963677, 'learning_rate': 'invscaling', 'eta0': 0.4513813627525124, 'power_t': 2.2262332485996383}. Best is trial 25 with value: 0.7839603929949722.\n",
      "[I 2024-10-14 20:00:05,959] Trial 29 finished with value: 0.7773205685716432 and parameters: {'nu': 0.3563449378356748, 'learning_rate': 'constant', 'eta0': 0.37048134792575965, 'power_t': 0.710138147373971}. Best is trial 25 with value: 0.7839603929949722.\n",
      "[I 2024-10-14 20:00:06,192] Trial 30 finished with value: 0.7853205008409643 and parameters: {'nu': 0.49916977844729304, 'learning_rate': 'optimal', 'eta0': 0.17453443540974412, 'power_t': 2.4816447936246755}. Best is trial 30 with value: 0.7853205008409643.\n",
      "[I 2024-10-14 20:00:06,418] Trial 31 finished with value: 0.7852821796805748 and parameters: {'nu': 0.4974020279737508, 'learning_rate': 'optimal', 'eta0': 0.1900084527091116, 'power_t': 2.477276137723667}. Best is trial 30 with value: 0.7853205008409643.\n",
      "[I 2024-10-14 20:00:06,654] Trial 32 finished with value: 0.7858605921420148 and parameters: {'nu': 0.49334748774511217, 'learning_rate': 'optimal', 'eta0': 0.16092283305661761, 'power_t': 2.5911982353852845}. Best is trial 32 with value: 0.7858605921420148.\n",
      "[I 2024-10-14 20:00:06,889] Trial 33 finished with value: 0.7860054874362512 and parameters: {'nu': 0.48345076277214416, 'learning_rate': 'optimal', 'eta0': 0.16711726747728423, 'power_t': 2.6282166606839574}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:07,131] Trial 34 finished with value: 0.7854666977539442 and parameters: {'nu': 0.4964498604880221, 'learning_rate': 'optimal', 'eta0': 0.16202055561989723, 'power_t': 2.655925678546688}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:07,354] Trial 35 finished with value: 0.7846241862910334 and parameters: {'nu': 0.47143155332268133, 'learning_rate': 'optimal', 'eta0': 0.14483186875346, 'power_t': 2.9690022314619586}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:07,607] Trial 36 finished with value: 0.733638831402693 and parameters: {'nu': 0.49691532598015237, 'learning_rate': 'invscaling', 'eta0': 0.043373325774469895, 'power_t': 1.6777201093084477}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:07,840] Trial 37 finished with value: 0.7845407942684207 and parameters: {'nu': 0.4631522595107107, 'learning_rate': 'optimal', 'eta0': 0.09924745801312444, 'power_t': 1.979543918801655}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:08,061] Trial 38 finished with value: 0.78126026978486 and parameters: {'nu': 0.42689039723190075, 'learning_rate': 'optimal', 'eta0': 0.15254368474114172, 'power_t': -0.3421604549522326}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:08,287] Trial 39 finished with value: 0.7704135223522576 and parameters: {'nu': 0.36892628247430315, 'learning_rate': 'optimal', 'eta0': 0.08082217906935754, 'power_t': 2.6254461981858737}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:10,516] Trial 40 finished with value: 0.5463882944884622 and parameters: {'nu': 0.46327552506585146, 'learning_rate': 'adaptive', 'eta0': 0.15339816866231815, 'power_t': 2.8218266514276875}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:10,740] Trial 41 finished with value: 0.7854763905749058 and parameters: {'nu': 0.49901690633872564, 'learning_rate': 'optimal', 'eta0': 0.1933634573799703, 'power_t': 2.5980236391207585}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:10,978] Trial 42 finished with value: 0.7854391849919244 and parameters: {'nu': 0.49407336835983173, 'learning_rate': 'optimal', 'eta0': 0.19408145020294143, 'power_t': 2.6576834358125656}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:11,220] Trial 43 finished with value: 0.7849230792981806 and parameters: {'nu': 0.46830353961032894, 'learning_rate': 'optimal', 'eta0': 0.2191092451639177, 'power_t': 1.8974717925237248}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:11,479] Trial 44 finished with value: 0.733638831402693 and parameters: {'nu': 0.1809953740410482, 'learning_rate': 'invscaling', 'eta0': 0.13456964854826303, 'power_t': 2.9672939810911454}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:11,711] Trial 45 finished with value: 0.7854919391057905 and parameters: {'nu': 0.4754204838268625, 'learning_rate': 'optimal', 'eta0': 0.26203742417684167, 'power_t': 2.6321295195986667}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:11,934] Trial 46 finished with value: 0.7680699194667353 and parameters: {'nu': 0.11136331475147174, 'learning_rate': 'optimal', 'eta0': 0.26882523768717725, 'power_t': -2.8841269655014443}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:12,159] Trial 47 finished with value: 0.7705623914407905 and parameters: {'nu': 0.2252961865267141, 'learning_rate': 'optimal', 'eta0': 0.2251270869141171, 'power_t': 2.6925517337589007}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:12,491] Trial 48 finished with value: 0.07413407526105407 and parameters: {'nu': 0.45598657762733996, 'learning_rate': 'constant', 'eta0': 0.2485131299664612, 'power_t': 1.4594920039361157}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:12,705] Trial 49 finished with value: 0.7855907289186066 and parameters: {'nu': 0.48171806312326426, 'learning_rate': 'optimal', 'eta0': 0.06856362756517406, 'power_t': 2.036555709950504}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:13,979] Trial 50 finished with value: 0.6378353376503237 and parameters: {'nu': 0.3765519446428576, 'learning_rate': 'adaptive', 'eta0': 0.008769138126266826, 'power_t': 0.7984530833012584}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:14,208] Trial 51 finished with value: 0.7811722940145829 and parameters: {'nu': 0.42126794390658184, 'learning_rate': 'optimal', 'eta0': 0.17545899512791566, 'power_t': 2.005610141065957}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:14,434] Trial 52 finished with value: 0.7850919576662312 and parameters: {'nu': 0.4770841481776254, 'learning_rate': 'optimal', 'eta0': 0.12474195382696038, 'power_t': 2.693495531701819}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:14,672] Trial 53 finished with value: 0.7845762855014934 and parameters: {'nu': 0.44756263837966004, 'learning_rate': 'optimal', 'eta0': 0.08227903263051525, 'power_t': 2.1626078617396125}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:14,892] Trial 54 finished with value: 0.7858660092717491 and parameters: {'nu': 0.4808256493676373, 'learning_rate': 'optimal', 'eta0': 0.31117621815431895, 'power_t': 2.522036356424564}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:15,118] Trial 55 finished with value: 0.7846893651235427 and parameters: {'nu': 0.4712233059066761, 'learning_rate': 'optimal', 'eta0': 0.2912361354236493, 'power_t': 1.8172465117169398}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:15,359] Trial 56 finished with value: 0.7851322726780772 and parameters: {'nu': 0.47769260714306827, 'learning_rate': 'optimal', 'eta0': 0.25831319301008987, 'power_t': 1.4741322507821977}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:15,599] Trial 57 finished with value: 0.733638831402693 and parameters: {'nu': 0.4205398808929231, 'learning_rate': 'invscaling', 'eta0': 0.31533815254230296, 'power_t': 2.368268427791302}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:15,837] Trial 58 finished with value: 0.7844821614132317 and parameters: {'nu': 0.4480413383135674, 'learning_rate': 'optimal', 'eta0': 0.33294528415314206, 'power_t': 2.0922158190768263}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:16,058] Trial 59 finished with value: 0.7694514905229217 and parameters: {'nu': 0.3229308010329799, 'learning_rate': 'optimal', 'eta0': 0.2076475372192676, 'power_t': 1.7796543401448248}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:16,303] Trial 60 finished with value: 0.7853973376361436 and parameters: {'nu': 0.478560775944642, 'learning_rate': 'optimal', 'eta0': 0.23553015283198125, 'power_t': -0.9075137860644034}. Best is trial 33 with value: 0.7860054874362512.\n",
      "[I 2024-10-14 20:00:16,518] Trial 61 finished with value: 0.786570111915734 and parameters: {'nu': 0.48598551500117676, 'learning_rate': 'optimal', 'eta0': 0.16982223748701453, 'power_t': 2.7993853886303635}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:16,747] Trial 62 finished with value: 0.7842061884257797 and parameters: {'nu': 0.4560479806907138, 'learning_rate': 'optimal', 'eta0': 0.09949870523638212, 'power_t': 2.8417957978864186}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:16,974] Trial 63 finished with value: 0.7835106831222756 and parameters: {'nu': 0.4353881667212373, 'learning_rate': 'optimal', 'eta0': 0.30458435508385406, 'power_t': 2.4306115413535223}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:17,212] Trial 64 finished with value: 0.7861518182523067 and parameters: {'nu': 0.4879515785420409, 'learning_rate': 'optimal', 'eta0': 0.17249554535004086, 'power_t': 0.16033634652419448}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:17,452] Trial 65 finished with value: 0.7864645010487535 and parameters: {'nu': 0.4841825400237349, 'learning_rate': 'optimal', 'eta0': 0.05594230652333866, 'power_t': 0.24184449219992513}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:17,685] Trial 66 finished with value: 0.7619899734424042 and parameters: {'nu': 0.01203627454132683, 'learning_rate': 'constant', 'eta0': 0.02575900352310584, 'power_t': 0.3515447750114813}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:17,932] Trial 67 finished with value: 0.773573980071442 and parameters: {'nu': 0.38624346289979206, 'learning_rate': 'optimal', 'eta0': 0.0587615170931232, 'power_t': 0.046245835934272256}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:21,293] Trial 68 finished with value: 0.6376926679290615 and parameters: {'nu': 0.4843942290496657, 'learning_rate': 'adaptive', 'eta0': 0.066734341666711, 'power_t': -0.20460221222268493}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:21,524] Trial 69 finished with value: 0.7845549738219896 and parameters: {'nu': 0.45541448484861013, 'learning_rate': 'optimal', 'eta0': 0.115508175346315, 'power_t': -0.9420815996527183}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:21,757] Trial 70 finished with value: 0.7802377742743772 and parameters: {'nu': 0.41314976245015655, 'learning_rate': 'optimal', 'eta0': 0.17221820925606193, 'power_t': 0.8287073933764992}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:21,994] Trial 71 finished with value: 0.7857192556571756 and parameters: {'nu': 0.4824952036012453, 'learning_rate': 'optimal', 'eta0': 0.03551750444581761, 'power_t': -1.6161804359898404}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:22,231] Trial 72 finished with value: 0.7855845788517949 and parameters: {'nu': 0.48569753251336806, 'learning_rate': 'optimal', 'eta0': 0.030396248025819226, 'power_t': -1.3892557158523853}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:22,474] Trial 73 finished with value: 0.7835745747207724 and parameters: {'nu': 0.4379699610288908, 'learning_rate': 'optimal', 'eta0': 0.08037919044183936, 'power_t': -2.1913487838249184}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:22,716] Trial 74 finished with value: 0.784487406608642 and parameters: {'nu': 0.4601555103320853, 'learning_rate': 'optimal', 'eta0': 0.01600335271396061, 'power_t': -0.6784853987669404}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:22,958] Trial 75 finished with value: 0.7863230645261265 and parameters: {'nu': 0.48506990864681926, 'learning_rate': 'optimal', 'eta0': 0.13543070994657125, 'power_t': -2.1945705183244475}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:23,193] Trial 76 finished with value: 0.7827440038632827 and parameters: {'nu': 0.43023109570330736, 'learning_rate': 'optimal', 'eta0': 0.13058490483596455, 'power_t': -2.0899633439818714}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:23,514] Trial 77 finished with value: 0.0 and parameters: {'nu': 0.4886751622689345, 'learning_rate': 'invscaling', 'eta0': 0.10566259408777723, 'power_t': -2.556248798595196}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:23,736] Trial 78 finished with value: 0.7848279055409786 and parameters: {'nu': 0.46530112706539456, 'learning_rate': 'optimal', 'eta0': 0.13754630191583686, 'power_t': -1.587807299467532}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:24,021] Trial 79 finished with value: 0.7649306829674313 and parameters: {'nu': 0.4490542445301681, 'learning_rate': 'constant', 'eta0': 0.20903639395148538, 'power_t': 0.22078108325533358}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:24,251] Trial 80 finished with value: 0.7789424113992314 and parameters: {'nu': 0.4098397303093669, 'learning_rate': 'optimal', 'eta0': 0.16067245374131, 'power_t': -2.317471808037064}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:24,483] Trial 81 finished with value: 0.785481980548462 and parameters: {'nu': 0.48627085183213953, 'learning_rate': 'optimal', 'eta0': 0.06570353769847315, 'power_t': -0.5662809354131113}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:24,712] Trial 82 finished with value: 0.784645946217526 and parameters: {'nu': 0.4702625603662203, 'learning_rate': 'optimal', 'eta0': 0.0421029759035948, 'power_t': -1.7933261553567577}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:24,941] Trial 83 finished with value: 0.7858873974645787 and parameters: {'nu': 0.4986497971746883, 'learning_rate': 'optimal', 'eta0': 0.0008577989623197169, 'power_t': 0.5225611267023655}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:25,182] Trial 84 finished with value: 0.7853940280848148 and parameters: {'nu': 0.4989684194807751, 'learning_rate': 'optimal', 'eta0': 0.024642040795036124, 'power_t': 0.22357160147576627}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:25,406] Trial 85 finished with value: 0.7840531561461794 and parameters: {'nu': 0.4417322386122999, 'learning_rate': 'optimal', 'eta0': 0.17883596096060597, 'power_t': -0.18973504114260442}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:25,635] Trial 86 finished with value: 0.7852570591991528 and parameters: {'nu': 0.4998118762857261, 'learning_rate': 'optimal', 'eta0': 0.038899869254868075, 'power_t': 0.5442876610000603}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:27,845] Trial 87 finished with value: 0.5952334098611567 and parameters: {'nu': 0.46308637606312747, 'learning_rate': 'adaptive', 'eta0': 0.05489791699981512, 'power_t': 0.9908591187515758}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:28,087] Trial 88 finished with value: 0.7858633018202124 and parameters: {'nu': 0.4855482736147134, 'learning_rate': 'optimal', 'eta0': 0.00836721082884128, 'power_t': -1.2565427800273414}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:28,337] Trial 89 finished with value: 0.7705040721989874 and parameters: {'nu': 0.24876221159266387, 'learning_rate': 'optimal', 'eta0': 0.0033418230053746494, 'power_t': -1.1430844010043948}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:28,587] Trial 90 finished with value: 0.7845314977377316 and parameters: {'nu': 0.47072214584152755, 'learning_rate': 'optimal', 'eta0': 0.0023362301629902293, 'power_t': -0.040942622331360506}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:28,818] Trial 91 finished with value: 0.7864128834260737 and parameters: {'nu': 0.48925266255340755, 'learning_rate': 'optimal', 'eta0': 0.0893286480203819, 'power_t': -1.9054998194901172}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:29,067] Trial 92 finished with value: 0.785939220948451 and parameters: {'nu': 0.48842570350357767, 'learning_rate': 'optimal', 'eta0': 0.162169099596204, 'power_t': -1.9726198112247972}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:29,289] Trial 93 finished with value: 0.7846666717993332 and parameters: {'nu': 0.45651007017904766, 'learning_rate': 'optimal', 'eta0': 0.09319117035043713, 'power_t': -1.925259483941103}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:29,531] Trial 94 finished with value: 0.7855363337912408 and parameters: {'nu': 0.4876212566881269, 'learning_rate': 'optimal', 'eta0': 0.11764600253014429, 'power_t': -2.559263238069187}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:29,778] Trial 95 finished with value: 0.7852355212355212 and parameters: {'nu': 0.47437082312690093, 'learning_rate': 'optimal', 'eta0': 0.019504415016769354, 'power_t': -2.3984131307215777}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:30,105] Trial 96 finished with value: 0.0 and parameters: {'nu': 0.4904265965419787, 'learning_rate': 'invscaling', 'eta0': 0.14302526603124047, 'power_t': -1.3902729336518933}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:30,324] Trial 97 finished with value: 0.7844934813654582 and parameters: {'nu': 0.44689350953020857, 'learning_rate': 'optimal', 'eta0': 0.20466111856537433, 'power_t': -2.0101828063586464}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:30,551] Trial 98 finished with value: 0.7687702417103659 and parameters: {'nu': 0.16292803504365616, 'learning_rate': 'optimal', 'eta0': 0.1235392506290101, 'power_t': 0.5291122483818582}. Best is trial 61 with value: 0.786570111915734.\n",
      "[I 2024-10-14 20:00:30,796] Trial 99 finished with value: 0.7057826691292675 and parameters: {'nu': 0.11868349134696943, 'learning_rate': 'constant', 'eta0': 0.1851093253021014, 'power_t': -1.7579579135509404}. Best is trial 61 with value: 0.786570111915734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'nu': 0.48598551500117676, 'learning_rate': 'optimal', 'eta0': 0.16982223748701453, 'power_t': 2.7993853886303635}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    nu = trial.suggest_float('nu', 0.01, 0.5)  \n",
    "    learning_rate = trial.suggest_categorical('learning_rate', ['constant', 'optimal', 'invscaling', 'adaptive'])\n",
    "    eta0 = trial.suggest_float('eta0', 1e-6, 0.5)\n",
    "    power_t = trial.suggest_float('power_t', -3, 3)\n",
    "\n",
    "    sgdocsvm = SGDOneClassSVM(nu=nu, learning_rate=learning_rate, eta0=eta0, power_t=power_t)\n",
    "    sgdocsvm.fit(train_latent_features)\n",
    "\n",
    "    val_predictions = sgdocsvm.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 1, -1)\n",
    "\n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=1, average='binary')\n",
    "\n",
    "    return f1 \n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1d89118e-8269-41ec-adcd-8bd4677b8545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7075\n",
      "Test Precision: 0.6823\n",
      "Test Recall: 0.9266\n",
      "Test F1 Score: 0.7859\n"
     ]
    }
   ],
   "source": [
    "best_sgdocsvm = SGDOneClassSVM(nu=best_params['nu'], \n",
    "                               learning_rate=best_params['learning_rate'], \n",
    "                               eta0=best_params['eta0'], \n",
    "                               random_state=42)\n",
    "\n",
    "best_sgdocsvm.fit(train_latent_features)\n",
    "\n",
    "test_predictions = best_sgdocsvm.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 1, -1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b521b47-305c-48fd-b20a-f0b764722ed3",
   "metadata": {},
   "source": [
    "# LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3cc2aae-3699-4c98-a567-ed96c7f69434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cd6e114-9389-42f9-b8a5-e32b62385ee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-17 09:55:03,569] A new study created in memory with name: no-name-aa890a24-4bdf-4bdf-abd6-313531285738\n",
      "[I 2024-11-17 09:58:06,419] Trial 0 finished with value: 0.9472733838931022 and parameters: {'n_neighbors': 36, 'leaf_size': 48, 'metric': 'manhattan'}. Best is trial 0 with value: 0.9472733838931022.\n",
      "[I 2024-11-17 09:58:35,920] Trial 1 finished with value: 0.9544910453564703 and parameters: {'n_neighbors': 29, 'leaf_size': 49, 'metric': 'euclidean'}. Best is trial 1 with value: 0.9544910453564703.\n",
      "[I 2024-11-17 09:59:05,709] Trial 2 finished with value: 0.8692248318447459 and parameters: {'n_neighbors': 44, 'leaf_size': 25, 'metric': 'euclidean'}. Best is trial 1 with value: 0.9544910453564703.\n",
      "[I 2024-11-17 10:02:09,829] Trial 3 finished with value: 0.9251770593623628 and parameters: {'n_neighbors': 22, 'leaf_size': 30, 'metric': 'manhattan'}. Best is trial 1 with value: 0.9544910453564703.\n",
      "[I 2024-11-17 10:02:39,490] Trial 4 finished with value: 0.9635298447947979 and parameters: {'n_neighbors': 33, 'leaf_size': 49, 'metric': 'minkowski'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:06:25,031] Trial 5 finished with value: 0.9502204275462596 and parameters: {'n_neighbors': 35, 'leaf_size': 26, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:10:13,106] Trial 6 finished with value: 0.9502204275462596 and parameters: {'n_neighbors': 35, 'leaf_size': 28, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:13:18,006] Trial 7 finished with value: 0.869975446243827 and parameters: {'n_neighbors': 46, 'leaf_size': 47, 'metric': 'manhattan'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:16:23,600] Trial 8 finished with value: 0.8692247778827 and parameters: {'n_neighbors': 44, 'leaf_size': 44, 'metric': 'manhattan'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:16:53,193] Trial 9 finished with value: 0.9535208153868437 and parameters: {'n_neighbors': 27, 'leaf_size': 27, 'metric': 'minkowski'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:17:21,723] Trial 10 finished with value: 0.8610460687787401 and parameters: {'n_neighbors': 6, 'leaf_size': 40, 'metric': 'minkowski'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:17:50,879] Trial 11 finished with value: 0.8965276819499016 and parameters: {'n_neighbors': 17, 'leaf_size': 38, 'metric': 'euclidean'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:18:20,342] Trial 12 finished with value: 0.9540021344717182 and parameters: {'n_neighbors': 28, 'leaf_size': 50, 'metric': 'minkowski'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:18:49,250] Trial 13 finished with value: 0.8965276819499016 and parameters: {'n_neighbors': 17, 'leaf_size': 43, 'metric': 'euclidean'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:19:18,627] Trial 14 finished with value: 0.9552063646893861 and parameters: {'n_neighbors': 30, 'leaf_size': 20, 'metric': 'euclidean'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:19:48,608] Trial 15 finished with value: 0.8922754440132566 and parameters: {'n_neighbors': 39, 'leaf_size': 21, 'metric': 'minkowski'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:20:18,173] Trial 16 finished with value: 0.938166247003302 and parameters: {'n_neighbors': 23, 'leaf_size': 33, 'metric': 'euclidean'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:20:46,932] Trial 17 finished with value: 0.8810720990957941 and parameters: {'n_neighbors': 8, 'leaf_size': 21, 'metric': 'minkowski'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:24:33,682] Trial 18 finished with value: 0.9627847264396799 and parameters: {'n_neighbors': 31, 'leaf_size': 35, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:28:19,935] Trial 19 finished with value: 0.9189441924006985 and parameters: {'n_neighbors': 39, 'leaf_size': 35, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:32:05,398] Trial 20 finished with value: 0.8775283954232643 and parameters: {'n_neighbors': 50, 'leaf_size': 33, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:35:52,023] Trial 21 finished with value: 0.961985119275907 and parameters: {'n_neighbors': 32, 'leaf_size': 39, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:39:39,161] Trial 22 finished with value: 0.961985119275907 and parameters: {'n_neighbors': 32, 'leaf_size': 39, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:43:25,250] Trial 23 finished with value: 0.952450185179517 and parameters: {'n_neighbors': 24, 'leaf_size': 44, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:47:11,955] Trial 24 finished with value: 0.9189441924006985 and parameters: {'n_neighbors': 39, 'leaf_size': 36, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:50:58,016] Trial 25 finished with value: 0.8976972991040612 and parameters: {'n_neighbors': 18, 'leaf_size': 42, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:51:27,787] Trial 26 finished with value: 0.960354239035004 and parameters: {'n_neighbors': 34, 'leaf_size': 32, 'metric': 'minkowski'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:55:12,241] Trial 27 finished with value: 0.961985119275907 and parameters: {'n_neighbors': 32, 'leaf_size': 46, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:58:57,636] Trial 28 finished with value: 0.9574303346237878 and parameters: {'n_neighbors': 26, 'leaf_size': 36, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 10:59:26,544] Trial 29 finished with value: 0.908816053709975 and parameters: {'n_neighbors': 12, 'leaf_size': 41, 'metric': 'minkowski'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:02:30,211] Trial 30 finished with value: 0.8703655118131982 and parameters: {'n_neighbors': 41, 'leaf_size': 46, 'metric': 'manhattan'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:06:16,954] Trial 31 finished with value: 0.9562514285714285 and parameters: {'n_neighbors': 33, 'leaf_size': 39, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:10:02,368] Trial 32 finished with value: 0.9627847264396799 and parameters: {'n_neighbors': 31, 'leaf_size': 37, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:13:49,076] Trial 33 finished with value: 0.9629515638825837 and parameters: {'n_neighbors': 30, 'leaf_size': 37, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:17:34,155] Trial 34 finished with value: 0.9629515638825837 and parameters: {'n_neighbors': 30, 'leaf_size': 35, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:21:20,413] Trial 35 finished with value: 0.9574303346237878 and parameters: {'n_neighbors': 26, 'leaf_size': 30, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:25:05,498] Trial 36 finished with value: 0.9346460497704759 and parameters: {'n_neighbors': 20, 'leaf_size': 24, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:28:10,104] Trial 37 finished with value: 0.9407844602166604 and parameters: {'n_neighbors': 37, 'leaf_size': 35, 'metric': 'manhattan'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:31:55,804] Trial 38 finished with value: 0.9623181713230201 and parameters: {'n_neighbors': 29, 'leaf_size': 30, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:32:25,473] Trial 39 finished with value: 0.9490763778933876 and parameters: {'n_neighbors': 36, 'leaf_size': 32, 'metric': 'minkowski'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:36:11,864] Trial 40 finished with value: 0.9539617099717759 and parameters: {'n_neighbors': 25, 'leaf_size': 48, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:39:59,150] Trial 41 finished with value: 0.9629515638825837 and parameters: {'n_neighbors': 30, 'leaf_size': 37, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:43:44,096] Trial 42 finished with value: 0.9610858754717271 and parameters: {'n_neighbors': 28, 'leaf_size': 34, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:47:29,644] Trial 43 finished with value: 0.9629515638825837 and parameters: {'n_neighbors': 30, 'leaf_size': 37, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:50:34,402] Trial 44 finished with value: 0.9154515079768991 and parameters: {'n_neighbors': 21, 'leaf_size': 37, 'metric': 'manhattan'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:54:20,097] Trial 45 finished with value: 0.9502204275462596 and parameters: {'n_neighbors': 35, 'leaf_size': 40, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:54:49,968] Trial 46 finished with value: 0.9544910453564703 and parameters: {'n_neighbors': 29, 'leaf_size': 28, 'metric': 'minkowski'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:55:19,682] Trial 47 finished with value: 0.9469812087201167 and parameters: {'n_neighbors': 37, 'leaf_size': 42, 'metric': 'euclidean'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:59:08,323] Trial 48 finished with value: 0.9610858754717271 and parameters: {'n_neighbors': 28, 'leaf_size': 37, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9635298447947979.\n",
      "[I 2024-11-17 11:59:38,062] Trial 49 finished with value: 0.869198312236287 and parameters: {'n_neighbors': 43, 'leaf_size': 32, 'metric': 'minkowski'}. Best is trial 4 with value: 0.9635298447947979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_neighbors': 33, 'leaf_size': 49, 'metric': 'minkowski'}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 5, 50)  \n",
    "    leaf_size = trial.suggest_int('leaf_size', 20, 50) \n",
    "    metric = trial.suggest_categorical('metric', ['euclidean', 'manhattan', 'chebyshev', 'minkowski'])  \n",
    "\n",
    "    lof = LocalOutlierFactor(n_neighbors=n_neighbors, leaf_size=leaf_size, metric=metric, novelty=True)\n",
    "    lof.fit(train_latent_features)\n",
    "\n",
    "    val_predictions = lof.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 1, -1)\n",
    "\n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=1, average='binary')\n",
    "\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c86115c-11ed-46d1-9f2a-4b34c2a3c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'n_neighbors': 33, 'leaf_size': 49, 'metric': 'minkowski'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91fac012-f694-45cb-91d7-39b027c95cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9583\n",
      "Test Precision: 0.9616\n",
      "Test Recall: 0.9666\n",
      "Test F1 Score: 0.9641\n"
     ]
    }
   ],
   "source": [
    "best_lof = LocalOutlierFactor(n_neighbors=best_params['n_neighbors'], \n",
    "                              leaf_size=best_params['leaf_size'], \n",
    "                              metric=best_params['metric'], \n",
    "                              novelty=True)\n",
    "\n",
    "best_lof.fit(train_latent_features)\n",
    "\n",
    "test_predictions = best_lof.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 1, -1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50f716a6-874e-4b50-ab11-b3b85d7d5030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 4.9189999104 seconds\n",
      "Inference Time Avg: 0.0000350781 seconds\n"
     ]
    }
   ],
   "source": [
    "best_lof = LocalOutlierFactor(n_neighbors=best_params['n_neighbors'], \n",
    "                              leaf_size=best_params['leaf_size'], \n",
    "                              metric=best_params['metric'], \n",
    "                              novelty=True)\n",
    "\n",
    "best_lof.fit(train_latent_features)\n",
    "\n",
    "start_time = time.time()\n",
    "prediction = best_lof.predict(test_latent_features)\n",
    "end_time = time.time()\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "\n",
    "print(f\"Inference Time: {inference_time:.10f} seconds\")\n",
    "print(f\"Inference Time Avg: {inference_time/len(X_test):.10f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fdfb652-2185-4173-adc9-c09c9c0d1128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 4383/4383 [00:01<00:00, 3211.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 6.1877796650 seconds\n",
      "Inference Time Avg: 0.0000441259 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "test_latent_features = extract_latent_features(model, test_loader, device)\n",
    "\n",
    "prediction = best_lof.predict(test_latent_features)\n",
    "end_time = time.time()\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "\n",
    "print(f\"Inference Time: {inference_time:.10f} seconds\")\n",
    "print(f\"Inference Time Avg: {inference_time/len(X_test):.10f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8441d28b-5b9c-4a4c-89bb-a3cbc7355fbd",
   "metadata": {},
   "source": [
    "# IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "911a9fdb-288c-45d1-bdaf-39215145a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23c70397-b155-4e23-a55e-a5991a950e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-14 19:47:01,539] A new study created in memory with name: no-name-0d31307d-5d1b-4547-b56b-b88557bccc92\n",
      "[I 2024-10-14 19:47:02,683] Trial 0 finished with value: 0.929471032745592 and parameters: {'n_estimators': 66, 'max_samples': 0.5236094005563003, 'contamination': 0.12585513456828093, 'max_features': 0.8034991029160704}. Best is trial 0 with value: 0.929471032745592.\n",
      "[I 2024-10-14 19:47:05,607] Trial 1 finished with value: 0.850907686365392 and parameters: {'n_estimators': 170, 'max_samples': 0.6834453163286682, 'contamination': 0.2431526104521451, 'max_features': 0.7855988078788745}. Best is trial 0 with value: 0.929471032745592.\n",
      "[I 2024-10-14 19:47:07,353] Trial 2 finished with value: 0.6751280338454687 and parameters: {'n_estimators': 106, 'max_samples': 0.6283744245157854, 'contamination': 0.4769975562277751, 'max_features': 0.7488403680178777}. Best is trial 0 with value: 0.929471032745592.\n",
      "[I 2024-10-14 19:47:09,774] Trial 3 finished with value: 0.8163914859757311 and parameters: {'n_estimators': 131, 'max_samples': 0.5646163144281358, 'contamination': 0.29254262918778823, 'max_features': 0.9017288451204213}. Best is trial 0 with value: 0.929471032745592.\n",
      "[I 2024-10-14 19:47:11,201] Trial 4 finished with value: 0.9144316730523627 and parameters: {'n_estimators': 99, 'max_samples': 0.6818263366192725, 'contamination': 0.14952571271386866, 'max_features': 0.5576409280398525}. Best is trial 0 with value: 0.929471032745592.\n",
      "[I 2024-10-14 19:47:15,496] Trial 5 finished with value: 0.6908690869086909 and parameters: {'n_estimators': 265, 'max_samples': 0.7575123930846088, 'contamination': 0.46098288886280425, 'max_features': 0.6912915961647654}. Best is trial 0 with value: 0.929471032745592.\n",
      "[I 2024-10-14 19:47:17,970] Trial 6 finished with value: 0.8681757656458056 and parameters: {'n_estimators': 148, 'max_samples': 0.9769252403272006, 'contamination': 0.2197351292999019, 'max_features': 0.6915963964901873}. Best is trial 0 with value: 0.929471032745592.\n",
      "[I 2024-10-14 19:47:21,707] Trial 7 finished with value: 0.6968900569426194 and parameters: {'n_estimators': 252, 'max_samples': 0.5858510470296567, 'contamination': 0.45270278579505596, 'max_features': 0.6331968275017608}. Best is trial 0 with value: 0.929471032745592.\n",
      "[I 2024-10-14 19:47:24,604] Trial 8 finished with value: 0.9003880983182406 and parameters: {'n_estimators': 169, 'max_samples': 0.8168574475540403, 'contamination': 0.16988278228366685, 'max_features': 0.7567200518826434}. Best is trial 0 with value: 0.929471032745592.\n",
      "[I 2024-10-14 19:47:27,099] Trial 9 finished with value: 0.7361937128292269 and parameters: {'n_estimators': 158, 'max_samples': 0.620720361975559, 'contamination': 0.39953580315626275, 'max_features': 0.70582551152947}. Best is trial 0 with value: 0.929471032745592.\n",
      "[I 2024-10-14 19:47:28,157] Trial 10 finished with value: 0.9143835616438356 and parameters: {'n_estimators': 51, 'max_samples': 0.8767476720769161, 'contamination': 0.011801074426501065, 'max_features': 0.9597447316273329}. Best is trial 0 with value: 0.929471032745592.\n",
      "[I 2024-10-14 19:47:29,131] Trial 11 finished with value: 0.9506172839506173 and parameters: {'n_estimators': 67, 'max_samples': 0.5090561291362544, 'contamination': 0.08262914778697326, 'max_features': 0.5415406116822044}. Best is trial 11 with value: 0.9506172839506173.\n",
      "[I 2024-10-14 19:47:29,897] Trial 12 finished with value: 0.98168748930344 and parameters: {'n_estimators': 54, 'max_samples': 0.5127115806655365, 'contamination': 0.030286162235774752, 'max_features': 0.5038894862978454}. Best is trial 12 with value: 0.98168748930344.\n",
      "[I 2024-10-14 19:47:32,878] Trial 13 finished with value: 0.911014312383323 and parameters: {'n_estimators': 223, 'max_samples': 0.5203856358473508, 'contamination': 0.013217654365729685, 'max_features': 0.5071289311071179}. Best is trial 12 with value: 0.98168748930344.\n",
      "[I 2024-10-14 19:47:34,098] Trial 14 finished with value: 0.9519112207151664 and parameters: {'n_estimators': 84, 'max_samples': 0.526524062857715, 'contamination': 0.08395435461006229, 'max_features': 0.5788596170364986}. Best is trial 12 with value: 0.98168748930344.\n",
      "[I 2024-10-14 19:47:35,547] Trial 15 finished with value: 0.9588801399825022 and parameters: {'n_estimators': 94, 'max_samples': 0.7294070730707074, 'contamination': 0.06519433440986339, 'max_features': 0.6176280606752783}. Best is trial 12 with value: 0.98168748930344.\n",
      "[I 2024-10-14 19:47:38,720] Trial 16 finished with value: 0.8085702843412095 and parameters: {'n_estimators': 206, 'max_samples': 0.9447659960866043, 'contamination': 0.30619222108368704, 'max_features': 0.6144994113898605}. Best is trial 12 with value: 0.98168748930344.\n",
      "[I 2024-10-14 19:47:42,855] Trial 17 finished with value: 0.9612430167597765 and parameters: {'n_estimators': 300, 'max_samples': 0.7572774001927145, 'contamination': 0.06444863272952839, 'max_features': 0.502747584263727}. Best is trial 12 with value: 0.98168748930344.\n",
      "[I 2024-10-14 19:47:46,791] Trial 18 finished with value: 0.8928172683289914 and parameters: {'n_estimators': 283, 'max_samples': 0.8163351085705763, 'contamination': 0.18151045876464605, 'max_features': 0.501992298845533}. Best is trial 12 with value: 0.98168748930344.\n",
      "[I 2024-10-14 19:47:50,818] Trial 19 finished with value: 0.9709443099273608 and parameters: {'n_estimators': 213, 'max_samples': 0.8113293009795283, 'contamination': 0.044722217062740315, 'max_features': 0.8756168504846658}. Best is trial 12 with value: 0.98168748930344.\n",
      "[I 2024-10-14 19:47:54,609] Trial 20 finished with value: 0.7759720222176507 and parameters: {'n_estimators': 201, 'max_samples': 0.8844467012578675, 'contamination': 0.3444888420516946, 'max_features': 0.8856682751968042}. Best is trial 12 with value: 0.98168748930344.\n",
      "[I 2024-10-14 19:48:00,077] Trial 21 finished with value: 0.9657569963497306 and parameters: {'n_estimators': 297, 'max_samples': 0.7919731114525974, 'contamination': 0.05369499860600485, 'max_features': 0.8583973812882026}. Best is trial 12 with value: 0.98168748930344.\n",
      "[I 2024-10-14 19:48:04,417] Trial 22 finished with value: 0.9371204001429082 and parameters: {'n_estimators': 236, 'max_samples': 0.8235772180636549, 'contamination': 0.11129987591188298, 'max_features': 0.8488843286432111}. Best is trial 12 with value: 0.98168748930344.\n",
      "[I 2024-10-14 19:48:08,329] Trial 23 finished with value: 0.9799417109549117 and parameters: {'n_estimators': 191, 'max_samples': 0.8665696064213682, 'contamination': 0.03118479148415348, 'max_features': 0.9794208875453051}. Best is trial 12 with value: 0.98168748930344.\n",
      "[I 2024-10-14 19:48:12,293] Trial 24 finished with value: 0.9842949812222601 and parameters: {'n_estimators': 195, 'max_samples': 0.8898080282090118, 'contamination': 0.024751095325244183, 'max_features': 0.9791516383038033}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:48:16,184] Trial 25 finished with value: 0.9308176100628931 and parameters: {'n_estimators': 190, 'max_samples': 0.8914392588153912, 'contamination': 0.11917533488125301, 'max_features': 0.9961770712038893}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:48:18,740] Trial 26 finished with value: 0.9547526041666666 and parameters: {'n_estimators': 127, 'max_samples': 0.931679915593401, 'contamination': 0.01120454889481419, 'max_features': 0.9441430605902638}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:48:22,350] Trial 27 finished with value: 0.8698955365622032 and parameters: {'n_estimators': 186, 'max_samples': 0.8482417066183519, 'contamination': 0.21694802562311816, 'max_features': 0.9302468033841653}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:48:25,319] Trial 28 finished with value: 0.9410927211247553 and parameters: {'n_estimators': 145, 'max_samples': 0.9979464917445755, 'contamination': 0.10032204016742267, 'max_features': 0.9918462090021543}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:48:29,762] Trial 29 finished with value: 0.9191643960036331 and parameters: {'n_estimators': 241, 'max_samples': 0.9323247260051226, 'contamination': 0.13898788024580278, 'max_features': 0.8205466181891508}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:48:32,107] Trial 30 finished with value: 0.9773117909934685 and parameters: {'n_estimators': 123, 'max_samples': 0.7004989221236597, 'contamination': 0.03504512923392021, 'max_features': 0.9054777687968448}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:48:34,298] Trial 31 finished with value: 0.9718334197338863 and parameters: {'n_estimators': 112, 'max_samples': 0.7042181454290128, 'contamination': 0.04643653457881831, 'max_features': 0.9151451777612278}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:48:37,798] Trial 32 finished with value: 0.9778388593025253 and parameters: {'n_estimators': 180, 'max_samples': 0.6559109523674658, 'contamination': 0.035826726641825006, 'max_features': 0.9682156970691513}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:48:41,237] Trial 33 finished with value: 0.9504321749867701 and parameters: {'n_estimators': 174, 'max_samples': 0.6565450487869164, 'contamination': 0.0866002639829136, 'max_features': 0.9691977825589121}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:48:44,818] Trial 34 finished with value: 0.9780144280316042 and parameters: {'n_estimators': 184, 'max_samples': 0.5530518422198882, 'contamination': 0.035219491463619634, 'max_features': 0.9692051067040096}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:48:48,654] Trial 35 finished with value: 0.9211242067089755 and parameters: {'n_estimators': 224, 'max_samples': 0.5548786999061911, 'contamination': 0.1377424384929206, 'max_features': 0.8033563027579882}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:48:52,574] Trial 36 finished with value: 0.8995746254854818 and parameters: {'n_estimators': 199, 'max_samples': 0.592426909975568, 'contamination': 0.17314023838738674, 'max_features': 0.9999014166664213}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:48:55,435] Trial 37 finished with value: 0.957420711407044 and parameters: {'n_estimators': 153, 'max_samples': 0.5519166216151759, 'contamination': 0.07105924813720405, 'max_features': 0.9324581830835722}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:48:58,144] Trial 38 finished with value: 0.9352183249821046 and parameters: {'n_estimators': 166, 'max_samples': 0.5003258298604569, 'contamination': 0.11039548033776256, 'max_features': 0.7393801610283012}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:49:00,665] Trial 39 finished with value: 0.9774875408145729 and parameters: {'n_estimators': 141, 'max_samples': 0.9057347826956611, 'contamination': 0.0357065191901485, 'max_features': 0.8381576400315585}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:49:03,552] Trial 40 finished with value: 0.6547592132037079 and parameters: {'n_estimators': 190, 'max_samples': 0.7820429016518645, 'contamination': 0.49837398351793016, 'max_features': 0.650816252873284}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:49:07,027] Trial 41 finished with value: 0.9813388118472864 and parameters: {'n_estimators': 185, 'max_samples': 0.630836673424537, 'contamination': 0.029424033674952103, 'max_features': 0.9676303677658902}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:49:11,286] Trial 42 finished with value: 0.9110972956170345 and parameters: {'n_estimators': 216, 'max_samples': 0.5878764954805382, 'contamination': 0.011534879061596386, 'max_features': 0.965663193849386}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:49:14,583] Trial 43 finished with value: 0.9794168096054888 and parameters: {'n_estimators': 163, 'max_samples': 0.6176919258307364, 'contamination': 0.03174019826374197, 'max_features': 0.9426334740796608}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:49:17,770] Trial 44 finished with value: 0.9474615248540598 and parameters: {'n_estimators': 163, 'max_samples': 0.6122501857408864, 'contamination': 0.09350405698415927, 'max_features': 0.8842008295953265}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:49:22,936] Trial 45 finished with value: 0.9619678995115143 and parameters: {'n_estimators': 256, 'max_samples': 0.6448370403422277, 'contamination': 0.06348251274638514, 'max_features': 0.9459999301424634}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:49:24,440] Trial 46 finished with value: 0.8305817610062893 and parameters: {'n_estimators': 82, 'max_samples': 0.7254104540894022, 'contamination': 0.2676008241707637, 'max_features': 0.7744343156308726}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:49:25,678] Trial 47 finished with value: 0.9795918367346939 and parameters: {'n_estimators': 59, 'max_samples': 0.8436119390319287, 'contamination': 0.030284755511930356, 'max_features': 0.9181553718371135}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:49:26,649] Trial 48 finished with value: 0.7386050455798177 and parameters: {'n_estimators': 52, 'max_samples': 0.8517353552584699, 'contamination': 0.39013466137028135, 'max_features': 0.7199423200517152}. Best is trial 24 with value: 0.9842949812222601.\n",
      "[I 2024-10-14 19:49:27,792] Trial 49 finished with value: 0.9552238805970149 and parameters: {'n_estimators': 65, 'max_samples': 0.8593017118059828, 'contamination': 0.0745582312733465, 'max_features': 0.6737515314415461}. Best is trial 24 with value: 0.9842949812222601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 195, 'max_samples': 0.8898080282090118, 'contamination': 0.024751095325244183, 'max_features': 0.9791516383038033}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)  \n",
    "    max_samples = trial.suggest_float('max_samples', 0.5, 1.0)  \n",
    "    contamination = trial.suggest_float('contamination', 0.01, 0.5) \n",
    "    max_features = trial.suggest_float('max_features', 0.5, 1.0)\n",
    "\n",
    "    iso_forest = IsolationForest(n_estimators=n_estimators, \n",
    "                                 max_samples=max_samples, \n",
    "                                 contamination=contamination, \n",
    "                                 max_features=max_features, \n",
    "                                 random_state=42)\n",
    "\n",
    "    iso_forest.fit(train_latent_features)\n",
    "    \n",
    "    val_predictions = iso_forest.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 1, -1)\n",
    "\n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=1, average='binary')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a3644c6-1377-47c0-8ee4-c20004ebfbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9989\n",
      "Test Precision: 1.0000\n",
      "Test Recall: 0.9661\n",
      "Test F1 Score: 0.9828\n"
     ]
    }
   ],
   "source": [
    "best_iso_forest = IsolationForest(n_estimators=best_params['n_estimators'], \n",
    "                                  max_samples=best_params['max_samples'], \n",
    "                                  contamination=best_params['contamination'], \n",
    "                                  max_features=best_params['max_features'], \n",
    "                                  random_state=42)\n",
    "\n",
    "best_iso_forest.fit(train_latent_features)\n",
    "test_predictions = best_iso_forest.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 1, -1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ef4cde-53bb-4472-bd95-1bb2f7006af8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# PCA Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "24b7360e-1ebb-4321-9001-47d18424a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8c1875ce-4f29-4126-b38f-d1ac2f46ccc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-14 20:03:47,021] A new study created in memory with name: no-name-cee50f82-b54e-4d5d-a6b0-a38ec545d017\n",
      "[I 2024-10-14 20:03:47,123] Trial 0 finished with value: 0.9076966479443974 and parameters: {'n_components': 16, 'percentile': 97.2657629522282}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:47,230] Trial 1 finished with value: 0.8959730687817195 and parameters: {'n_components': 22, 'percentile': 96.58952607359136}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:47,311] Trial 2 finished with value: 0.8679493504357836 and parameters: {'n_components': 4, 'percentile': 91.9642128973525}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:47,407] Trial 3 finished with value: 0.8649346351150091 and parameters: {'n_components': 27, 'percentile': 95.7113205243859}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:47,520] Trial 4 finished with value: 0.7560861560043254 and parameters: {'n_components': 31, 'percentile': 94.80703196722598}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:47,628] Trial 5 finished with value: 0.8893422332997593 and parameters: {'n_components': 23, 'percentile': 95.40296307558633}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:47,714] Trial 6 finished with value: 0.8055534965086801 and parameters: {'n_components': 9, 'percentile': 99.50311703463723}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:47,786] Trial 7 finished with value: 0.8174187922389361 and parameters: {'n_components': 3, 'percentile': 96.17853469531015}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:47,876] Trial 8 finished with value: 0.8979860084226182 and parameters: {'n_components': 20, 'percentile': 95.18622854236541}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:47,980] Trial 9 finished with value: 0.9061272284494828 and parameters: {'n_components': 18, 'percentile': 97.82120289124445}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:48,076] Trial 10 finished with value: 0.9014776134008238 and parameters: {'n_components': 13, 'percentile': 92.8523695698131}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:48,186] Trial 11 finished with value: 0.8783941023784144 and parameters: {'n_components': 15, 'percentile': 98.81953360262129}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:48,284] Trial 12 finished with value: 0.8680516108090562 and parameters: {'n_components': 11, 'percentile': 97.943399376692}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:48,388] Trial 13 finished with value: 0.9062818855860145 and parameters: {'n_components': 18, 'percentile': 97.6360129108062}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:48,492] Trial 14 finished with value: 0.9049859408597211 and parameters: {'n_components': 17, 'percentile': 90.25171666722287}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:48,584] Trial 15 finished with value: 0.8648239734495998 and parameters: {'n_components': 8, 'percentile': 97.42341935357602}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:48,687] Trial 16 finished with value: 0.7401666711908576 and parameters: {'n_components': 25, 'percentile': 99.88713933942597}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:48,792] Trial 17 finished with value: 0.9066209556460253 and parameters: {'n_components': 15, 'percentile': 96.91530725054467}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:48,890] Trial 18 finished with value: 0.8857999689767498 and parameters: {'n_components': 6, 'percentile': 94.15065792776697}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:48,979] Trial 19 finished with value: 0.8999991214892514 and parameters: {'n_components': 14, 'percentile': 93.88605230734989}. Best is trial 0 with value: 0.9076966479443974.\n",
      "[I 2024-10-14 20:03:49,079] Trial 20 finished with value: 0.9077347923710223 and parameters: {'n_components': 12, 'percentile': 96.6681354510959}. Best is trial 20 with value: 0.9077347923710223.\n",
      "[I 2024-10-14 20:03:49,173] Trial 21 finished with value: 0.890328668559537 and parameters: {'n_components': 11, 'percentile': 96.81707594775501}. Best is trial 20 with value: 0.9077347923710223.\n",
      "[I 2024-10-14 20:03:49,276] Trial 22 finished with value: 0.8794256891648536 and parameters: {'n_components': 15, 'percentile': 98.80057006354478}. Best is trial 20 with value: 0.9077347923710223.\n",
      "[I 2024-10-14 20:03:49,373] Trial 23 finished with value: 0.907728699840867 and parameters: {'n_components': 12, 'percentile': 96.68086896837714}. Best is trial 20 with value: 0.9077347923710223.\n",
      "[I 2024-10-14 20:03:49,467] Trial 24 finished with value: 0.8996690501911964 and parameters: {'n_components': 10, 'percentile': 96.123963003489}. Best is trial 20 with value: 0.9077347923710223.\n",
      "[I 2024-10-14 20:03:49,549] Trial 25 finished with value: 0.7743471007823286 and parameters: {'n_components': 6, 'percentile': 98.60844696083353}. Best is trial 20 with value: 0.9077347923710223.\n",
      "[I 2024-10-14 20:03:49,638] Trial 26 finished with value: 0.905916277921322 and parameters: {'n_components': 12, 'percentile': 94.13007813512077}. Best is trial 20 with value: 0.9077347923710223.\n",
      "[I 2024-10-14 20:03:49,735] Trial 27 finished with value: 0.8711775332566924 and parameters: {'n_components': 7, 'percentile': 97.13813107351169}. Best is trial 20 with value: 0.9077347923710223.\n",
      "[I 2024-10-14 20:03:49,832] Trial 28 finished with value: 0.8906918865107019 and parameters: {'n_components': 20, 'percentile': 98.3056359854654}. Best is trial 20 with value: 0.9077347923710223.\n",
      "[I 2024-10-14 20:03:49,939] Trial 29 finished with value: 0.9014173930949276 and parameters: {'n_components': 21, 'percentile': 96.26203508655492}. Best is trial 20 with value: 0.9077347923710223.\n",
      "[I 2024-10-14 20:03:50,041] Trial 30 finished with value: 0.9121245828698554 and parameters: {'n_components': 17, 'percentile': 94.73012502061916}. Best is trial 30 with value: 0.9121245828698554.\n",
      "[I 2024-10-14 20:03:50,143] Trial 31 finished with value: 0.9116011876965912 and parameters: {'n_components': 17, 'percentile': 94.85495364816796}. Best is trial 30 with value: 0.9121245828698554.\n",
      "[I 2024-10-14 20:03:50,247] Trial 32 finished with value: 0.9146333791665543 and parameters: {'n_components': 17, 'percentile': 93.33817912542237}. Best is trial 32 with value: 0.9146333791665543.\n",
      "[I 2024-10-14 20:03:50,347] Trial 33 finished with value: 0.9101335343527891 and parameters: {'n_components': 16, 'percentile': 92.9773138541928}. Best is trial 32 with value: 0.9146333791665543.\n",
      "[I 2024-10-14 20:03:50,451] Trial 34 finished with value: 0.9131902449591133 and parameters: {'n_components': 17, 'percentile': 92.79792879198368}. Best is trial 32 with value: 0.9146333791665543.\n",
      "[I 2024-10-14 20:03:50,559] Trial 35 finished with value: 0.8928803713504219 and parameters: {'n_components': 23, 'percentile': 91.89532892484559}. Best is trial 32 with value: 0.9146333791665543.\n",
      "[I 2024-10-14 20:03:50,666] Trial 36 finished with value: 0.9162097821382196 and parameters: {'n_components': 19, 'percentile': 93.12634087757516}. Best is trial 36 with value: 0.9162097821382196.\n",
      "[I 2024-10-14 20:03:50,777] Trial 37 finished with value: 0.8844159051617684 and parameters: {'n_components': 27, 'percentile': 91.94050142085204}. Best is trial 36 with value: 0.9162097821382196.\n",
      "[I 2024-10-14 20:03:50,884] Trial 38 finished with value: 0.916121807607557 and parameters: {'n_components': 19, 'percentile': 92.9186044123729}. Best is trial 36 with value: 0.9162097821382196.\n",
      "[I 2024-10-14 20:03:50,992] Trial 39 finished with value: 0.9093515458081481 and parameters: {'n_components': 19, 'percentile': 91.20555543252009}. Best is trial 36 with value: 0.9162097821382196.\n",
      "[I 2024-10-14 20:03:51,106] Trial 40 finished with value: 0.8913087386825674 and parameters: {'n_components': 23, 'percentile': 93.03417149993984}. Best is trial 36 with value: 0.9162097821382196.\n",
      "[I 2024-10-14 20:03:51,215] Trial 41 finished with value: 0.9095432991363612 and parameters: {'n_components': 21, 'percentile': 92.50858580676957}. Best is trial 36 with value: 0.9162097821382196.\n",
      "[I 2024-10-14 20:03:51,321] Trial 42 finished with value: 0.9179247576093121 and parameters: {'n_components': 18, 'percentile': 93.49417867388266}. Best is trial 42 with value: 0.9179247576093121.\n",
      "[I 2024-10-14 20:03:51,429] Trial 43 finished with value: 0.8781104801239029 and parameters: {'n_components': 25, 'percentile': 93.61623044703057}. Best is trial 42 with value: 0.9179247576093121.\n",
      "[I 2024-10-14 20:03:51,535] Trial 44 finished with value: 0.9164418060802303 and parameters: {'n_components': 19, 'percentile': 93.3917872011025}. Best is trial 42 with value: 0.9179247576093121.\n",
      "[I 2024-10-14 20:03:51,645] Trial 45 finished with value: 0.916670411749373 and parameters: {'n_components': 19, 'percentile': 93.4684339604641}. Best is trial 42 with value: 0.9179247576093121.\n",
      "[I 2024-10-14 20:03:51,752] Trial 46 finished with value: 0.9143717298851096 and parameters: {'n_components': 19, 'percentile': 92.40922406958691}. Best is trial 42 with value: 0.9179247576093121.\n",
      "[I 2024-10-14 20:03:51,863] Trial 47 finished with value: 0.8951846770972616 and parameters: {'n_components': 22, 'percentile': 94.44067645092169}. Best is trial 42 with value: 0.9179247576093121.\n",
      "[I 2024-10-14 20:03:51,975] Trial 48 finished with value: 0.8839886314026318 and parameters: {'n_components': 25, 'percentile': 91.05365875291878}. Best is trial 42 with value: 0.9179247576093121.\n",
      "[I 2024-10-14 20:03:52,094] Trial 49 finished with value: 0.7190265639334763 and parameters: {'n_components': 32, 'percentile': 95.4375222732271}. Best is trial 42 with value: 0.9179247576093121.\n",
      "[I 2024-10-14 20:03:52,200] Trial 50 finished with value: 0.9077721313955661 and parameters: {'n_components': 20, 'percentile': 93.44930859635623}. Best is trial 42 with value: 0.9179247576093121.\n",
      "[I 2024-10-14 20:03:52,310] Trial 51 finished with value: 0.9167954569960105 and parameters: {'n_components': 19, 'percentile': 93.50604925396806}. Best is trial 42 with value: 0.9179247576093121.\n",
      "[I 2024-10-14 20:03:52,420] Trial 52 finished with value: 0.9087526640898747 and parameters: {'n_components': 21, 'percentile': 92.30359331137937}. Best is trial 42 with value: 0.9179247576093121.\n",
      "[I 2024-10-14 20:03:52,525] Trial 53 finished with value: 0.9168189145620634 and parameters: {'n_components': 19, 'percentile': 93.84046021871102}. Best is trial 42 with value: 0.9179247576093121.\n",
      "[I 2024-10-14 20:03:52,629] Trial 54 finished with value: 0.9181145893164848 and parameters: {'n_components': 18, 'percentile': 93.81720464587612}. Best is trial 54 with value: 0.9181145893164848.\n",
      "[I 2024-10-14 20:03:52,730] Trial 55 finished with value: 0.8998655500584374 and parameters: {'n_components': 14, 'percentile': 93.8184985558283}. Best is trial 54 with value: 0.9181145893164848.\n",
      "[I 2024-10-14 20:03:52,834] Trial 56 finished with value: 0.9186790818922803 and parameters: {'n_components': 18, 'percentile': 94.37750202751906}. Best is trial 56 with value: 0.9186790818922803.\n",
      "[I 2024-10-14 20:03:52,936] Trial 57 finished with value: 0.908840534934016 and parameters: {'n_components': 16, 'percentile': 94.35362050130513}. Best is trial 56 with value: 0.9186790818922803.\n",
      "[I 2024-10-14 20:03:53,040] Trial 58 finished with value: 0.9132363034793475 and parameters: {'n_components': 18, 'percentile': 95.21915379403485}. Best is trial 56 with value: 0.9186790818922803.\n",
      "[I 2024-10-14 20:03:53,142] Trial 59 finished with value: 0.8999991214892514 and parameters: {'n_components': 14, 'percentile': 93.88599432113402}. Best is trial 56 with value: 0.9186790818922803.\n",
      "[I 2024-10-14 20:03:53,258] Trial 60 finished with value: 0.8955285355117171 and parameters: {'n_components': 22, 'percentile': 95.62183186580891}. Best is trial 56 with value: 0.9186790818922803.\n",
      "[I 2024-10-14 20:03:53,364] Trial 61 finished with value: 0.9182798955892703 and parameters: {'n_components': 18, 'percentile': 94.53483880808284}. Best is trial 56 with value: 0.9186790818922803.\n",
      "[I 2024-10-14 20:03:53,470] Trial 62 finished with value: 0.9179300460246949 and parameters: {'n_components': 18, 'percentile': 94.57480829608653}. Best is trial 56 with value: 0.9186790818922803.\n",
      "[I 2024-10-14 20:03:53,575] Trial 63 finished with value: 0.9024805808700819 and parameters: {'n_components': 15, 'percentile': 94.58712079460557}. Best is trial 56 with value: 0.9186790818922803.\n",
      "[I 2024-10-14 20:03:53,680] Trial 64 finished with value: 0.9085839055060111 and parameters: {'n_components': 16, 'percentile': 94.98868532678684}. Best is trial 56 with value: 0.9186790818922803.\n",
      "[I 2024-10-14 20:03:53,788] Trial 65 finished with value: 0.9187317099363708 and parameters: {'n_components': 18, 'percentile': 94.15336450328901}. Best is trial 65 with value: 0.9187317099363708.\n",
      "[I 2024-10-14 20:03:53,898] Trial 66 finished with value: 0.9188720251138082 and parameters: {'n_components': 18, 'percentile': 94.22376422766509}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:54,004] Trial 67 finished with value: 0.9187864038580261 and parameters: {'n_components': 18, 'percentile': 94.18068503703805}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:54,110] Trial 68 finished with value: 0.9071912879116306 and parameters: {'n_components': 16, 'percentile': 95.9003717478594}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:54,211] Trial 69 finished with value: 0.9044225049715784 and parameters: {'n_components': 13, 'percentile': 94.20378771295603}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:54,319] Trial 70 finished with value: 0.910706446344847 and parameters: {'n_components': 17, 'percentile': 95.1010789727082}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:54,424] Trial 71 finished with value: 0.9188115623070936 and parameters: {'n_components': 18, 'percentile': 94.19222420212351}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:54,530] Trial 72 finished with value: 0.9188038012062208 and parameters: {'n_components': 18, 'percentile': 94.16865720537804}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:54,640] Trial 73 finished with value: 0.9066579634464752 and parameters: {'n_components': 21, 'percentile': 94.2070472892333}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:54,746] Trial 74 finished with value: 0.8998329388834748 and parameters: {'n_components': 20, 'percentile': 94.80256418017754}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:54,854] Trial 75 finished with value: 0.9024088021020995 and parameters: {'n_components': 15, 'percentile': 94.05543627074549}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:54,962] Trial 76 finished with value: 0.9129039913510473 and parameters: {'n_components': 18, 'percentile': 95.29768136736693}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:55,067] Trial 77 finished with value: 0.9033514310022717 and parameters: {'n_components': 20, 'percentile': 94.38371889323005}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:55,171] Trial 78 finished with value: 0.9082218141239116 and parameters: {'n_components': 16, 'percentile': 94.77375133842105}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:55,277] Trial 79 finished with value: 0.9180086401235843 and parameters: {'n_components': 18, 'percentile': 93.74714133801768}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:55,363] Trial 80 finished with value: 0.8711394918852291 and parameters: {'n_components': 2, 'percentile': 93.21242890901809}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:55,459] Trial 81 finished with value: 0.9181031386913739 and parameters: {'n_components': 18, 'percentile': 93.78972230726697}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:55,568] Trial 82 finished with value: 0.9137041361055905 and parameters: {'n_components': 17, 'percentile': 94.0154228088108}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:55,677] Trial 83 finished with value: 0.9181227179624187 and parameters: {'n_components': 18, 'percentile': 94.55716502100351}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:55,784] Trial 84 finished with value: 0.9024017066368238 and parameters: {'n_components': 15, 'percentile': 94.53877789276012}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:55,897] Trial 85 finished with value: 0.9063676355205276 and parameters: {'n_components': 21, 'percentile': 94.22982119554796}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:56,010] Trial 86 finished with value: 0.8896075487883337 and parameters: {'n_components': 23, 'percentile': 95.00976245861229}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:56,116] Trial 87 finished with value: 0.909216063851107 and parameters: {'n_components': 17, 'percentile': 95.65152033056951}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:56,225] Trial 88 finished with value: 0.9007937200174444 and parameters: {'n_components': 20, 'percentile': 94.65737288890855}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:56,324] Trial 89 finished with value: 0.9050692845662656 and parameters: {'n_components': 14, 'percentile': 95.48266157574079}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:56,434] Trial 90 finished with value: 0.8988955573706453 and parameters: {'n_components': 22, 'percentile': 92.77482395499378}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:56,539] Trial 91 finished with value: 0.9181613039530346 and parameters: {'n_components': 18, 'percentile': 93.67607781493889}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:56,642] Trial 92 finished with value: 0.9185231651581683 and parameters: {'n_components': 18, 'percentile': 93.99455951937794}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:56,750] Trial 93 finished with value: 0.9126282466236887 and parameters: {'n_components': 17, 'percentile': 94.39256289944177}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:56,857] Trial 94 finished with value: 0.8993716704181043 and parameters: {'n_components': 20, 'percentile': 94.86986608793065}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:56,961] Trial 95 finished with value: 0.9087942973162276 and parameters: {'n_components': 16, 'percentile': 93.99805113308912}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:57,071] Trial 96 finished with value: 0.9175364685292605 and parameters: {'n_components': 18, 'percentile': 93.25109160263067}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:57,179] Trial 97 finished with value: 0.9170630706208891 and parameters: {'n_components': 19, 'percentile': 94.189303599168}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:57,281] Trial 98 finished with value: 0.9087835733921692 and parameters: {'n_components': 16, 'percentile': 93.62125755843189}. Best is trial 66 with value: 0.9188720251138082.\n",
      "[I 2024-10-14 20:03:57,386] Trial 99 finished with value: 0.9170793401973708 and parameters: {'n_components': 19, 'percentile': 94.4295004640961}. Best is trial 66 with value: 0.9188720251138082.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_components': 18, 'percentile': 94.22376422766509}\n"
     ]
    }
   ],
   "source": [
    "def reconstruction_error(X, pca):\n",
    "    X_pca = pca.transform(X)\n",
    "    X_reconstructed = pca.inverse_transform(X_pca)\n",
    "    return np.mean((X - X_reconstructed) ** 2, axis=1)\n",
    "    \n",
    "def objective(trial):\n",
    "    n_components = trial.suggest_int('n_components', 2, min(train_latent_features.shape[1], 50))\n",
    "    percentile = trial.suggest_float('percentile', 90.0, 99.9)  \n",
    "\n",
    "    pca = PCA(n_components=n_components, whiten=True, svd_solver='auto')\n",
    "\n",
    "    normal_data_pca = pca.fit_transform(train_latent_features)\n",
    "    normal_data_reconstructed = pca.inverse_transform(normal_data_pca)\n",
    "\n",
    "    reconstruction_errors = np.mean((train_latent_features - normal_data_reconstructed) ** 2, axis=1)\n",
    "    threshold = np.percentile(reconstruction_errors, percentile)\n",
    "    val_reconstruction_errors = reconstruction_error(val_latent_features, pca)\n",
    "    val_predictions = np.where(val_reconstruction_errors > threshold, -1, 1)\n",
    "\n",
    "    val_true_labels = np.where(y_val == 0, 1, -1)\n",
    "\n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=1, average='binary')\n",
    "\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "283e41bb-dbaa-40ff-b9a8-593c994a7314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9049\n",
      "Test Precision: 0.8979\n",
      "Test Recall: 0.9430\n",
      "Test F1 Score: 0.9199\n"
     ]
    }
   ],
   "source": [
    "best_pca = PCA(n_components=best_params['n_components'], whiten=True, svd_solver='auto')\n",
    "\n",
    "normal_data_pca = best_pca.fit_transform(train_latent_features)\n",
    "normal_data_reconstructed = best_pca.inverse_transform(normal_data_pca)\n",
    "\n",
    "reconstruction_errors = np.mean((train_latent_features - normal_data_reconstructed) ** 2, axis=1)\n",
    "\n",
    "threshold = np.percentile(reconstruction_errors, best_params['percentile'])\n",
    "\n",
    "test_pca = best_pca.transform(test_latent_features)\n",
    "test_reconstructed = best_pca.inverse_transform(test_pca)\n",
    "test_reconstruction_errors = np.mean((test_latent_features - test_reconstructed) ** 2, axis=1)\n",
    "\n",
    "test_predictions = np.where(test_reconstruction_errors > threshold, -1, 1) \n",
    "\n",
    "test_true_labels = np.where(y_test == 0, 1, -1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7082049-f195-4faa-9382-492825a0070a",
   "metadata": {},
   "source": [
    "# DIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8209e5d1-b061-4284-a459-4cbb9d30b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import DeepIsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ca9b5bc-dbc0-4a24-98af-88d685a4e5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Inference on the training data...\n",
      "Start Inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:44<00:00,  8.09s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<deepod.models.tabular.dif.DeepIsolationForest at 0x7ff6f0284650>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif_model = DeepIsolationForest(epochs=10)\n",
    "\n",
    "dif_model.fit(train_latent_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "012b62c4-fd7b-4cfa-8225-bcb3c06e59b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:33<00:00,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8884\n",
      "Test Precision: 0.8708\n",
      "Test Recall: 0.8626\n",
      "Test F1 Score: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = dif_model.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a10a22-863d-4329-8b37-625a88390c9f",
   "metadata": {},
   "source": [
    "# SLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2577f03-0cbc-4b7c-80a1-66dccd34acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import SLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c95fef30-c09f-4386-b4f4-e723a00c3ac8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:09:17,097] A new study created in memory with name: no-name-5638df5c-6ce7-4c30-a734-d1db508714eb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 18\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.546880, time: 0.8s\n",
      "epoch 10, training loss: 0.525268, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:10:16,255] Trial 0 finished with value: 0.9420341394025604 and parameters: {'epochs': 19, 'hidden_dims': 85, 'n_slad_ensemble': 18}. Best is trial 0 with value: 0.9420341394025604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.574282, time: 0.5s\n",
      "epoch 10, training loss: 0.555246, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:11:27,673] Trial 1 finished with value: 0.9416577730345073 and parameters: {'epochs': 19, 'hidden_dims': 121, 'n_slad_ensemble': 20}. Best is trial 0 with value: 0.9420341394025604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 46\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.604720, time: 0.5s\n",
      "epoch 10, training loss: 0.575029, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:13:35,592] Trial 2 finished with value: 0.9450354609929078 and parameters: {'epochs': 18, 'hidden_dims': 112, 'n_slad_ensemble': 46}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 27\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.602454, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:14:48,645] Trial 3 finished with value: 0.9437244807385052 and parameters: {'epochs': 4, 'hidden_dims': 61, 'n_slad_ensemble': 27}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 43\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.614494, time: 0.5s\n",
      "epoch 10, training loss: 0.576331, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:16:57,551] Trial 4 finished with value: 0.9420341394025604 and parameters: {'epochs': 16, 'hidden_dims': 88, 'n_slad_ensemble': 43}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 11\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.549502, time: 0.7s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:17:34,613] Trial 5 finished with value: 0.940149625935162 and parameters: {'epochs': 5, 'hidden_dims': 85, 'n_slad_ensemble': 11}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 15\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.631303, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:18:24,721] Trial 6 finished with value: 0.9384478144513827 and parameters: {'epochs': 8, 'hidden_dims': 140, 'n_slad_ensemble': 15}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 46\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.606754, time: 0.5s\n",
      "epoch 10, training loss: 0.575114, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:20:47,051] Trial 7 finished with value: 0.9437244807385052 and parameters: {'epochs': 19, 'hidden_dims': 93, 'n_slad_ensemble': 46}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 28\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.603501, time: 0.6s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:22:14,489] Trial 8 finished with value: 0.9448483773718744 and parameters: {'epochs': 4, 'hidden_dims': 124, 'n_slad_ensemble': 28}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 50\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.570713, time: 0.5s\n",
      "epoch 10, training loss: 0.537132, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:24:24,971] Trial 9 finished with value: 0.9433493162848517 and parameters: {'epochs': 17, 'hidden_dims': 116, 'n_slad_ensemble': 50}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 38\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.614227, time: 0.6s\n",
      "epoch 10, training loss: 0.578234, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:26:23,448] Trial 10 finished with value: 0.9429738852371646 and parameters: {'epochs': 12, 'hidden_dims': 57, 'n_slad_ensemble': 38}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 32\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.605320, time: 0.7s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:28:02,578] Trial 11 finished with value: 0.9414694894146949 and parameters: {'epochs': 1, 'hidden_dims': 147, 'n_slad_ensemble': 32}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 28\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.605510, time: 0.5s\n",
      "epoch 10, training loss: 0.582747, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:29:36,005] Trial 12 finished with value: 0.9439119630812921 and parameters: {'epochs': 12, 'hidden_dims': 120, 'n_slad_ensemble': 28}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 35\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.611072, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:31:13,899] Trial 13 finished with value: 0.9429738852371646 and parameters: {'epochs': 9, 'hidden_dims': 109, 'n_slad_ensemble': 35}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 25\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.528649, time: 0.5s\n",
      "epoch 10, training loss: 0.507894, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:32:27,350] Trial 14 finished with value: 0.9424102381798791 and parameters: {'epochs': 14, 'hidden_dims': 135, 'n_slad_ensemble': 25}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 39\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.565083, time: 0.6s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:34:15,093] Trial 15 finished with value: 0.9437244807385052 and parameters: {'epochs': 6, 'hidden_dims': 132, 'n_slad_ensemble': 39}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 32\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.607866, time: 0.6s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:35:48,062] Trial 16 finished with value: 0.9437244807385052 and parameters: {'epochs': 3, 'hidden_dims': 102, 'n_slad_ensemble': 32}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 24\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.544181, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:37:04,659] Trial 17 finished with value: 0.9409042363830544 and parameters: {'epochs': 8, 'hidden_dims': 127, 'n_slad_ensemble': 24}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 42\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.577456, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:39:07,427] Trial 18 finished with value: 0.934612031386225 and parameters: {'epochs': 1, 'hidden_dims': 73, 'n_slad_ensemble': 42}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 50\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.572632, time: 0.5s\n",
      "epoch 10, training loss: 0.537129, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:41:49,310] Trial 19 finished with value: 0.9420341394025604 and parameters: {'epochs': 15, 'hidden_dims': 105, 'n_slad_ensemble': 50}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 22\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.552064, time: 0.5s\n",
      "epoch 10, training loss: 0.534214, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:42:57,323] Trial 20 finished with value: 0.9427860696517413 and parameters: {'epochs': 11, 'hidden_dims': 148, 'n_slad_ensemble': 22}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 30\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.605949, time: 0.6s\n",
      "epoch 10, training loss: 0.582007, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:44:36,938] Trial 21 finished with value: 0.9439119630812921 and parameters: {'epochs': 13, 'hidden_dims': 116, 'n_slad_ensemble': 30}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 28\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.605358, time: 0.6s\n",
      "epoch 10, training loss: 0.582842, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:46:07,181] Trial 22 finished with value: 0.9437244807385052 and parameters: {'epochs': 10, 'hidden_dims': 125, 'n_slad_ensemble': 28}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 35\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.609375, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:47:54,870] Trial 23 finished with value: 0.9418459896852214 and parameters: {'epochs': 7, 'hidden_dims': 112, 'n_slad_ensemble': 35}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 35\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.612610, time: 0.6s\n",
      "epoch 10, training loss: 0.586125, time: 0.6s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:49:54,456] Trial 24 finished with value: 0.9414694894146949 and parameters: {'epochs': 17, 'hidden_dims': 100, 'n_slad_ensemble': 35}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 28\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.604424, time: 0.6s\n",
      "epoch 10, training loss: 0.582741, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-06 22:50:39,122] Trial 25 failed with parameters: {'epochs': 11, 'hidden_dims': 136, 'n_slad_ensemble': 28} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_165/313744358.py\", line 13, in objective\n",
      "    val_predictions = slad_model.predict(val_latent_features)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/deepod/core/base_model.py\", line 264, in predict\n",
      "    pred_score = self.decision_function(X)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/deepod/models/tabular/slad.py\", line 118, in decision_function\n",
      "    for batch_x in test_loader:\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
      "    self._IterableDataset_len_called is not None and \\\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 675, in _next_data\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
      "    )\n",
      "      \n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
      "    )\n",
      "      \n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 209, in __getitem__\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 209, in <genexpr>\n",
      "KeyboardInterrupt\n",
      "[W 2024-10-06 22:50:39,128] Trial 25 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f1\n\u001b[1;32m     19\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[44], line 13\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      6\u001b[0m slad_model \u001b[38;5;241m=\u001b[39m SLAD(epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m      7\u001b[0m                   hidden_dims\u001b[38;5;241m=\u001b[39mhidden_dims,\n\u001b[1;32m      8\u001b[0m                   n_slad_ensemble\u001b[38;5;241m=\u001b[39mn_slad_ensemble,\n\u001b[1;32m      9\u001b[0m                   random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     11\u001b[0m slad_model\u001b[38;5;241m.\u001b[39mfit(train_latent_features)\n\u001b[0;32m---> 13\u001b[0m val_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mslad_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_latent_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m val_true_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y_val \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(val_true_labels, val_predictions, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/deepod/core/base_model.py:264\u001b[0m, in \u001b[0;36mBaseDeepAD.predict\u001b[0;34m(self, X, return_confidence)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, return_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict if a particular sample is an outlier or not.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m        Only if return_confidence is set to True.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m     pred_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m (pred_score \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold_)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_confidence:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/deepod/models/tabular/slad.py:118\u001b[0m, in \u001b[0;36mSLAD.decision_function\u001b[0;34m(self, X, return_rep)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    117\u001b[0m     score_lst \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 118\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_lst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m--> 631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n\u001b[1;32m    633\u001b[0m     warn_msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of IterableDataset \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was reported to be \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m (when accessing len(dataloader)), but \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    634\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples have been fetched. \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called,\n\u001b[1;32m    635\u001b[0m                                                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded)\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, auto_collation, collate_fn, drop_last):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_MapDatasetFetcher, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     50\u001b[0m         dataset, auto_collation, collate_fn, drop_last\n\u001b[0;32m---> 51\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, auto_collation, collate_fn, drop_last):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_MapDatasetFetcher, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     50\u001b[0m         dataset, auto_collation, collate_fn, drop_last\n\u001b[0;32m---> 51\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataset.py:209\u001b[0m, in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataset.py:209\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    epochs = trial.suggest_int('epochs', 1, 20)\n",
    "    hidden_dims = trial.suggest_int('hidden_dims', 50, 150)\n",
    "    n_slad_ensemble = trial.suggest_int('n_slad_ensemble', 10, 50)\n",
    "\n",
    "    slad_model = SLAD(epochs=epochs,\n",
    "                      hidden_dims=hidden_dims,\n",
    "                      n_slad_ensemble=n_slad_ensemble,\n",
    "                      random_state=42)\n",
    "\n",
    "    slad_model.fit(train_latent_features)\n",
    "    \n",
    "    val_predictions = slad_model.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 0, 1)\n",
    "    \n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=0, average='binary')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "434d901b-e83b-4c99-806f-4ca25d705522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 46\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.604720, time: 0.5s\n",
      "epoch 10, training loss: 0.575029, time: 0.6s\n",
      "Start Inference on the training data...\n",
      "Test Accuracy: 0.9967\n",
      "Test Precision: 0.9966\n",
      "Test Recall: 1.0000\n",
      "Test F1 Score: 0.9983\n"
     ]
    }
   ],
   "source": [
    "best_slad_model = SLAD(epochs=best_params['epochs'],\n",
    "                      hidden_dims=best_params['hidden_dims'],\n",
    "                      n_slad_ensemble=best_params['n_slad_ensemble'],\n",
    "                      random_state=42)\n",
    "\n",
    "best_slad_model.fit(train_latent_features)\n",
    "test_predictions = best_slad_model.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af788c-a570-4474-bbad-4dde854db763",
   "metadata": {},
   "source": [
    "# ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b87cd445-45a2-45e6-80aa-78576c8acefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81d5bccf-e83b-425b-a33c-86b33bf2bf5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 23:23:19,739] A new study created in memory with name: no-name-e8bc4f88-11e5-4639-9142-9081f1e932a0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.977962, time: 1.1s\n",
      "epoch 10, training loss: 0.016990, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.144904, time: 1.0s\n",
      "epoch 10, training loss: 0.024965, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.007313, time: 1.0s\n",
      "epoch 10, training loss: 0.023104, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 424.44it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 425.99it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 424.00it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 395.67it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 426.71it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 426.26it/s]\n",
      "[I 2024-10-06 23:24:22,499] Trial 0 finished with value: 0.9472753007784855 and parameters: {'epochs': 17, 'rep_dim': 81, 'temperature': 0.0760299845415369}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=107, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=107, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.931543, time: 1.0s\n",
      "epoch 10, training loss: 0.012359, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=107, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=107, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.084916, time: 1.0s\n",
      "epoch 10, training loss: 0.020836, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=107, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=107, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.911327, time: 1.0s\n",
      "epoch 10, training loss: 0.012301, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 428.26it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 430.69it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.83it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 398.70it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 429.69it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 430.39it/s]\n",
      "[I 2024-10-06 23:25:16,293] Trial 1 finished with value: 0.9416577730345073 and parameters: {'epochs': 14, 'rep_dim': 107, 'temperature': 0.07259122025301018}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=120, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=120, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.076359, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=120, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=120, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.916763, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=120, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=120, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.931595, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.78it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.96it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 431.49it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 399.75it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 431.39it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 431.02it/s]\n",
      "[I 2024-10-06 23:25:40,284] Trial 2 finished with value: 0.9442867281760113 and parameters: {'epochs': 4, 'rep_dim': 120, 'temperature': 0.0766664466294853}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=123, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=123, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.068955, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=123, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=123, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.096130, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=123, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=123, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.170599, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 427.89it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.29it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.01it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 398.32it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 428.79it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 428.11it/s]\n",
      "[I 2024-10-06 23:26:07,333] Trial 3 finished with value: 0.9437244807385052 and parameters: {'epochs': 5, 'rep_dim': 123, 'temperature': 0.04544801196510964}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=106, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=106, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 4.168003, time: 1.0s\n",
      "epoch 10, training loss: 0.042935, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=106, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=106, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 3.123611, time: 1.0s\n",
      "epoch 10, training loss: 0.050678, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=106, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=106, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 4.182095, time: 1.0s\n",
      "epoch 10, training loss: 0.046395, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.39it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 427.39it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 427.82it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 397.38it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 394.77it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 424.91it/s]\n",
      "[I 2024-10-06 23:26:55,530] Trial 4 finished with value: 0.9444740109987582 and parameters: {'epochs': 12, 'rep_dim': 106, 'temperature': 0.006371459908374069}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=89, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=89, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.062504, time: 1.0s\n",
      "epoch 10, training loss: 0.015328, time: 1.0s\n",
      "epoch 20, training loss: 0.008720, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=89, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=89, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.219382, time: 1.0s\n",
      "epoch 10, training loss: 0.045529, time: 1.0s\n",
      "epoch 20, training loss: 0.008698, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=89, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=89, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.074838, time: 1.0s\n",
      "epoch 10, training loss: 0.016221, time: 1.0s\n",
      "epoch 20, training loss: 0.009236, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.62it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 431.38it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 432.74it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 403.06it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 432.18it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 432.38it/s]\n",
      "[I 2024-10-06 23:28:07,850] Trial 5 finished with value: 0.9439119630812921 and parameters: {'epochs': 20, 'rep_dim': 89, 'temperature': 0.06439632148942298}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=64, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=64, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.971719, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=64, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=64, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.075491, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=64, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=64, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.960277, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 425.08it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 427.01it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 427.97it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 396.04it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 427.30it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 427.54it/s]\n",
      "[I 2024-10-06 23:28:31,998] Trial 6 finished with value: 0.9422222222222222 and parameters: {'epochs': 4, 'rep_dim': 64, 'temperature': 0.09312711821623763}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=68, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=68, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.212229, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=68, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=68, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.374729, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=68, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=68, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.134042, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 424.60it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 427.16it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 428.24it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 395.37it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 427.34it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 426.85it/s]\n",
      "[I 2024-10-06 23:29:05,169] Trial 7 finished with value: 0.9437244807385052 and parameters: {'epochs': 7, 'rep_dim': 68, 'temperature': 0.03579768469081826}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=115, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=115, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.894028, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=115, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=115, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.879942, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=115, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=115, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.015622, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.87it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 428.09it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.58it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 397.18it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 429.18it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 429.30it/s]\n",
      "[I 2024-10-06 23:29:38,283] Trial 8 finished with value: 0.9399608052734723 and parameters: {'epochs': 7, 'rep_dim': 115, 'temperature': 0.015152460304907509}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=59, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=59, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.246714, time: 1.0s\n",
      "epoch 10, training loss: 0.020210, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=59, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=59, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.139315, time: 1.0s\n",
      "epoch 10, training loss: 0.025434, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=59, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=59, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.067532, time: 1.0s\n",
      "epoch 10, training loss: 0.024247, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 423.37it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.31it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.79it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 394.63it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 426.96it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 429.76it/s]\n",
      "[I 2024-10-06 23:30:29,188] Trial 9 finished with value: 0.9412811387900356 and parameters: {'epochs': 13, 'rep_dim': 59, 'temperature': 0.05471622804229905}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=149, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=149, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.901904, time: 1.0s\n",
      "epoch 10, training loss: 0.012082, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=149, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=149, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.941494, time: 1.0s\n",
      "epoch 10, training loss: 0.011680, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=149, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=149, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.046349, time: 1.0s\n",
      "epoch 10, training loss: 0.035361, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 427.93it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 430.63it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 431.42it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 397.52it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 430.68it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 430.45it/s]\n",
      "[I 2024-10-06 23:31:37,905] Trial 10 finished with value: 0.9454094292803971 and parameters: {'epochs': 19, 'rep_dim': 149, 'temperature': 0.09442691311359701}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=150, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=150, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.895807, time: 1.0s\n",
      "epoch 10, training loss: 0.016461, time: 1.0s\n",
      "epoch 20, training loss: 0.005020, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=150, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=150, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.095167, time: 1.0s\n",
      "epoch 10, training loss: 0.014779, time: 1.0s\n",
      "epoch 20, training loss: 0.005448, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=150, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=150, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.996117, time: 1.0s\n",
      "epoch 10, training loss: 0.034899, time: 1.0s\n",
      "epoch 20, training loss: 0.022238, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 430.27it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 432.86it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 432.82it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 400.09it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 433.12it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 431.52it/s]\n",
      "[I 2024-10-06 23:32:49,421] Trial 11 finished with value: 0.9439119630812921 and parameters: {'epochs': 20, 'rep_dim': 150, 'temperature': 0.09303168401502951}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=88, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=88, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.896443, time: 1.0s\n",
      "epoch 10, training loss: 0.048338, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=88, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=88, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.877997, time: 1.0s\n",
      "epoch 10, training loss: 0.016088, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=88, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=88, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.981956, time: 1.0s\n",
      "epoch 10, training loss: 0.035822, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.33it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.20it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.56it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 397.03it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 428.76it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 427.73it/s]\n",
      "[I 2024-10-06 23:33:52,173] Trial 12 finished with value: 0.9418459896852214 and parameters: {'epochs': 17, 'rep_dim': 88, 'temperature': 0.09782295434976807}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=145, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=145, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.908918, time: 1.0s\n",
      "epoch 10, training loss: 0.011521, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=145, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=145, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.020715, time: 1.0s\n",
      "epoch 10, training loss: 0.014193, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=145, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=145, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.139361, time: 1.0s\n",
      "epoch 10, training loss: 0.039567, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 424.12it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.25it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.68it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 394.50it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 426.18it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 426.53it/s]\n",
      "[I 2024-10-06 23:34:51,996] Trial 13 finished with value: 0.9452224782839922 and parameters: {'epochs': 16, 'rep_dim': 145, 'temperature': 0.07895880484435379}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=84, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=84, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.917392, time: 1.0s\n",
      "epoch 10, training loss: 0.014112, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=84, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=84, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.004389, time: 1.0s\n",
      "epoch 10, training loss: 0.026795, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=84, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=84, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.985542, time: 1.0s\n",
      "epoch 10, training loss: 0.017831, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 427.94it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 431.48it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 431.03it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 398.33it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 430.39it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 430.89it/s]\n",
      "[I 2024-10-06 23:35:54,752] Trial 14 finished with value: 0.9455963140173667 and parameters: {'epochs': 17, 'rep_dim': 84, 'temperature': 0.08238244964319305}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=79, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=79, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.095969, time: 1.0s\n",
      "epoch 10, training loss: 0.018787, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=79, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=79, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.044516, time: 1.0s\n",
      "epoch 10, training loss: 0.052008, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=79, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=79, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.185235, time: 1.1s\n",
      "epoch 10, training loss: 0.021344, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 430.20it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 433.04it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 433.66it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 417.37it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 429.66it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 430.14it/s]\n",
      "[I 2024-10-06 23:36:54,476] Trial 15 finished with value: 0.9440993788819876 and parameters: {'epochs': 16, 'rep_dim': 79, 'temperature': 0.0612459374534487}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.066267, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.002778, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.189955, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 425.58it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.24it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.41it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 427.09it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 431.97it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 432.51it/s]\n",
      "[I 2024-10-06 23:37:09,363] Trial 16 finished with value: 0.9461565710237336 and parameters: {'epochs': 1, 'rep_dim': 51, 'temperature': 0.08196225508823195}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=54, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=54, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.387123, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=54, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=54, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.239975, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=54, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=54, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.290880, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 428.19it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 430.43it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 430.92it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 398.22it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 429.77it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 430.41it/s]\n",
      "[I 2024-10-06 23:37:48,197] Trial 17 finished with value: 0.9424102381798791 and parameters: {'epochs': 9, 'rep_dim': 54, 'temperature': 0.036600673008754636}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=72, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=72, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.033883, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=72, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=72, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.109952, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=72, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=72, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.916986, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 423.60it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.46it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 430.69it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 398.40it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 429.70it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 429.40it/s]\n",
      "[I 2024-10-06 23:38:03,378] Trial 18 finished with value: 0.9442867281760113 and parameters: {'epochs': 1, 'rep_dim': 72, 'temperature': 0.06409707765220436}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.060860, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.007660, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.185869, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 428.93it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 431.24it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 430.74it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 398.88it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 431.01it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 430.88it/s]\n",
      "[I 2024-10-06 23:38:18,528] Trial 19 finished with value: 0.9457831325301205 and parameters: {'epochs': 1, 'rep_dim': 51, 'temperature': 0.08336224816985124}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'epochs': 17, 'rep_dim': 81, 'temperature': 0.0760299845415369}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    epochs = trial.suggest_int('epochs', 1, 20)\n",
    "    rep_dim = trial.suggest_int('rep_dim', 50, 150)\n",
    "    temperature = trial.suggest_float('temperature', 0.001, 0.1)\n",
    "\n",
    "    icl_model = ICL(epochs=epochs,\n",
    "                      rep_dim=rep_dim,\n",
    "                      temperature=temperature,\n",
    "                      random_state=42)\n",
    "\n",
    "    icl_model.fit(train_latent_features)\n",
    "    \n",
    "    val_predictions = icl_model.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 0, 1)\n",
    "    \n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=0, average='binary')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c48a5ce5-b2b5-4981-ad13-6c7e386f3251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.977961, time: 1.0s\n",
      "epoch 10, training loss: 0.016990, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.144904, time: 1.0s\n",
      "epoch 10, training loss: 0.024965, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.007313, time: 1.0s\n",
      "epoch 10, training loss: 0.023104, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.23it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 431.81it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 432.38it/s]\n",
      "testing: 100%|██████████| 1841/1841 [00:04<00:00, 397.33it/s]\n",
      "testing: 100%|██████████| 1841/1841 [00:04<00:00, 427.12it/s]\n",
      "testing: 100%|██████████| 1841/1841 [00:04<00:00, 431.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9966\n",
      "Test Precision: 0.9965\n",
      "Test Recall: 1.0000\n",
      "Test F1 Score: 0.9983\n"
     ]
    }
   ],
   "source": [
    "best_icl_model = ICL(epochs=best_params['epochs'],\n",
    "                      rep_dim=best_params['rep_dim'],\n",
    "                      temperature=best_params['temperature'],\n",
    "                      random_state=42)\n",
    "\n",
    "best_icl_model.fit(train_latent_features)\n",
    "test_predictions = best_icl_model.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ce91ad-61ac-48f6-84a0-b13a7d744d27",
   "metadata": {},
   "source": [
    "# RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10352c8f-a071-483a-9a66-d482dbab6edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4210c16-4ca8-46b4-8717-3bbf948d8e69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:55:43,908] A new study created in memory with name: no-name-86e67b36-3a9b-4ed0-9276-c1c74fa4b4ca\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=67, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=67, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=67, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=67, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.263287, time: 1.1s\n",
      "beta: 0.99730279382521\n",
      "beta: 0.9946055876504201\n",
      "beta: 0.9919083814756301\n",
      "beta: 0.9892111753008401\n",
      "beta: 0.9865139691260502\n",
      "beta: 0.9838167629512602\n",
      "beta: 0.9811195567764702\n",
      "beta: 0.9811195567764701\n",
      "beta: 0.9811195567764701\n",
      "epoch 10, training loss: 0.760622, time: 1.1s\n",
      "beta: 0.9811195567764701\n",
      "beta: 0.9811195567764701\n",
      "beta: 0.9811195567764701\n",
      "beta: 0.9811195567764701\n",
      "beta: 0.9811195567764701\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.17it/s]\n",
      "100%|██████████| 10/10 [00:25<00:00,  2.53s/it]\n",
      "[I 2024-10-06 22:56:27,602] Trial 0 finished with value: 0.7559413690052654 and parameters: {'epochs': 14, 'rep_dim': 67, 'anom_ratio': 0.01888044322352994}. Best is trial 0 with value: 0.7559413690052654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=104, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=104, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=104, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=104, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.233222, time: 1.1s\n",
      "beta: 0.9921755846079604\n",
      "beta: 0.9843511692159208\n",
      "beta: 0.9765267538238812\n",
      "beta: 0.9687023384318416\n",
      "beta: 0.960877923039802\n",
      "beta: 0.9530535076477624\n",
      "beta: 0.9452290922557228\n",
      "beta: 0.9374046768636832\n",
      "beta: 0.9295802614716436\n",
      "epoch 10, training loss: 0.743092, time: 1.0s\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.62it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.22s/it]\n",
      "[I 2024-10-06 22:57:12,413] Trial 1 finished with value: 0.6529569238257483 and parameters: {'epochs': 19, 'rep_dim': 104, 'anom_ratio': 0.07433194622437658}. Best is trial 0 with value: 0.7559413690052654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=79, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=79, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=79, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=79, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.320945, time: 1.0s\n",
      "beta: 0.9817996350129625\n",
      "beta: 0.963599270025925\n",
      "beta: 0.9453989050388876\n",
      "beta: 0.9271985400518501\n",
      "beta: 0.9089981750648127\n",
      "beta: 0.9089981750648127\n",
      "beta: 0.9089981750648127\n",
      "beta: 0.9089981750648127\n",
      "beta: 0.9089981750648127\n",
      "epoch 10, training loss: 0.733890, time: 1.0s\n",
      "beta: 0.9089981750648127\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.61it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.21s/it]\n",
      "[I 2024-10-06 22:57:47,380] Trial 2 finished with value: 0.22217611420034858 and parameters: {'epochs': 10, 'rep_dim': 79, 'anom_ratio': 0.09100182493518726}. Best is trial 0 with value: 0.7559413690052654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=130, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=130, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=130, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=130, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.327385, time: 1.0s\n",
      "beta: 0.9952834785153132\n",
      "beta: 0.9905669570306264\n",
      "beta: 0.9858504355459395\n",
      "beta: 0.9811339140612527\n",
      "beta: 0.9764173925765659\n",
      "beta: 0.9717008710918791\n",
      "beta: 0.9669843496071925\n",
      "beta: 0.9669843496071925\n",
      "beta: 0.9669843496071925\n",
      "epoch 10, training loss: 0.731934, time: 1.0s\n",
      "beta: 0.9669843496071925\n",
      "beta: 0.9669843496071925\n",
      "beta: 0.9669843496071925\n",
      "beta: 0.9669843496071925\n",
      "beta: 0.9669843496071925\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.59it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.23s/it]\n",
      "[I 2024-10-06 22:58:26,526] Trial 3 finished with value: 0.755224735184655 and parameters: {'epochs': 14, 'rep_dim': 130, 'anom_ratio': 0.03301565039280751}. Best is trial 0 with value: 0.7559413690052654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=56, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=56, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=56, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=56, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.294371, time: 1.0s\n",
      "beta: 0.9792913249156269\n",
      "beta: 0.9585826498312537\n",
      "beta: 0.9378739747468806\n",
      "beta: 0.9171652996625075\n",
      "beta: 0.9068109621203209\n",
      "beta: 0.9068109621203209\n",
      "beta: 0.9068109621203209\n",
      "beta: 0.9068109621203209\n",
      "beta: 0.9068109621203209\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.63it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.20s/it]\n",
      "[I 2024-10-06 22:59:00,402] Trial 4 finished with value: 0.20754497968659316 and parameters: {'epochs': 9, 'rep_dim': 56, 'anom_ratio': 0.09318903787967915}. Best is trial 0 with value: 0.7559413690052654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=106, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=106, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=106, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=106, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.220599, time: 1.0s\n",
      "beta: 0.9905737816671508\n",
      "beta: 0.9811475633343016\n",
      "beta: 0.9717213450014525\n",
      "beta: 0.9622951266686033\n",
      "beta: 0.9528689083357541\n",
      "beta: 0.9434426900029049\n",
      "beta: 0.9340164716700557\n",
      "beta: 0.9245902533372066\n",
      "beta: 0.9151640350043574\n",
      "epoch 10, training loss: 0.790301, time: 1.0s\n",
      "beta: 0.9057378166715082\n",
      "beta: 0.905737816671508\n",
      "beta: 0.905737816671508\n",
      "beta: 0.905737816671508\n",
      "beta: 0.905737816671508\n",
      "beta: 0.905737816671508\n",
      "beta: 0.905737816671508\n",
      "beta: 0.905737816671508\n",
      "beta: 0.905737816671508\n",
      "beta: 0.905737816671508\n",
      "epoch 20, training loss: 0.684928, time: 1.0s\n",
      "beta: 0.905737816671508\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.59it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.23s/it]\n",
      "[I 2024-10-06 22:59:45,468] Trial 5 finished with value: 0.7847395451210565 and parameters: {'epochs': 20, 'rep_dim': 106, 'anom_ratio': 0.094262183328492}. Best is trial 5 with value: 0.7847395451210565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=139, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=139, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=139, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=139, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.190404, time: 1.0s\n",
      "beta: 0.9840968252404793\n",
      "beta: 0.9681936504809585\n",
      "beta: 0.9522904757214378\n",
      "beta: 0.936387300961917\n",
      "beta: 0.9204841262023965\n",
      "beta: 0.9204841262023965\n",
      "beta: 0.9204841262023965\n",
      "beta: 0.9204841262023965\n",
      "beta: 0.9204841262023965\n",
      "epoch 10, training loss: 0.725513, time: 1.0s\n",
      "beta: 0.9204841262023965\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.62it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.23s/it]\n",
      "[I 2024-10-06 23:00:20,624] Trial 6 finished with value: 0.2206297858400557 and parameters: {'epochs': 10, 'rep_dim': 139, 'anom_ratio': 0.0795158737976035}. Best is trial 5 with value: 0.7847395451210565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=146, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=146, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=146, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=146, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.335315, time: 1.0s\n",
      "beta: 0.9836796956571804\n",
      "beta: 0.9673593913143608\n",
      "beta: 0.9510390869715412\n",
      "beta: 0.9347187826287215\n",
      "beta: 0.9183984782859019\n",
      "beta: 0.9020781739430823\n",
      "beta: 0.9020781739430821\n",
      "beta: 0.9020781739430821\n",
      "beta: 0.9020781739430821\n",
      "epoch 10, training loss: 0.713542, time: 1.0s\n",
      "beta: 0.9020781739430821\n",
      "beta: 0.9020781739430821\n",
      "beta: 0.9020781739430821\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.58it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.25s/it]\n",
      "[I 2024-10-06 23:00:57,948] Trial 7 finished with value: 0.2228342513770656 and parameters: {'epochs': 12, 'rep_dim': 146, 'anom_ratio': 0.0979218260569179}. Best is trial 5 with value: 0.7847395451210565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=66, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=66, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=66, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=66, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.247700, time: 1.0s\n",
      "beta: 0.9889858668428918\n",
      "beta: 0.9779717336857836\n",
      "beta: 0.9669576005286754\n",
      "beta: 0.9559434673715672\n",
      "beta: 0.9504364007930133\n",
      "beta: 0.9504364007930133\n",
      "beta: 0.9504364007930133\n",
      "beta: 0.9504364007930133\n",
      "beta: 0.9504364007930133\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.63it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.20s/it]\n",
      "[I 2024-10-06 23:01:31,830] Trial 8 finished with value: 0.39871526740364505 and parameters: {'epochs': 9, 'rep_dim': 66, 'anom_ratio': 0.04956359920698668}. Best is trial 5 with value: 0.7847395451210565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.254296, time: 1.0s\n",
      "beta: 0.9898748165247435\n",
      "beta: 0.979749633049487\n",
      "beta: 0.9696244495742306\n",
      "beta: 0.9594992660989741\n",
      "beta: 0.9493740826237176\n",
      "beta: 0.9392488991484611\n",
      "beta: 0.9291237156732046\n",
      "beta: 0.9189985321979486\n",
      "beta: 0.9189985321979486\n",
      "epoch 10, training loss: 0.812544, time: 1.0s\n",
      "beta: 0.9189985321979486\n",
      "beta: 0.9189985321979486\n",
      "beta: 0.9189985321979486\n",
      "beta: 0.9189985321979486\n",
      "beta: 0.9189985321979486\n",
      "beta: 0.9189985321979486\n",
      "beta: 0.9189985321979486\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.62it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.20s/it]\n",
      "[I 2024-10-06 23:02:13,116] Trial 9 finished with value: 0.5359398496240602 and parameters: {'epochs': 16, 'rep_dim': 61, 'anom_ratio': 0.08100146780205145}. Best is trial 5 with value: 0.7847395451210565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=109, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=109, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=109, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=109, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.241487, time: 1.0s\n",
      "beta: 0.959951173510064\n",
      "beta: 0.9399267602650959\n",
      "beta: 0.9399267602650959\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.59it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.28s/it]\n",
      "[I 2024-10-06 23:02:41,926] Trial 10 finished with value: 0.2490763690782397 and parameters: {'epochs': 3, 'rep_dim': 109, 'anom_ratio': 0.0600732397349041}. Best is trial 5 with value: 0.7847395451210565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=91, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=91, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=91, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=91, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.253874, time: 1.0s\n",
      "beta: 0.9988366410920575\n",
      "beta: 0.997673282184115\n",
      "beta: 0.9965099232761725\n",
      "beta: 0.99534656436823\n",
      "beta: 0.9941832054602875\n",
      "beta: 0.993019846552345\n",
      "beta: 0.9918564876444025\n",
      "beta: 0.99069312873646\n",
      "beta: 0.9895297698285175\n",
      "epoch 10, training loss: 0.785605, time: 1.0s\n",
      "beta: 0.988366410920575\n",
      "beta: 0.9883664109205748\n",
      "beta: 0.9883664109205748\n",
      "beta: 0.9883664109205748\n",
      "beta: 0.9883664109205748\n",
      "beta: 0.9883664109205748\n",
      "beta: 0.9883664109205748\n",
      "beta: 0.9883664109205748\n",
      "beta: 0.9883664109205748\n",
      "beta: 0.9883664109205748\n",
      "epoch 20, training loss: 0.647848, time: 1.0s\n",
      "beta: 0.9883664109205748\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.60it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.22s/it]\n",
      "[I 2024-10-06 23:03:27,264] Trial 11 finished with value: 0.7854191263282172 and parameters: {'epochs': 20, 'rep_dim': 91, 'anom_ratio': 0.011633589079425279}. Best is trial 11 with value: 0.7854191263282172.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=89, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=89, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=89, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=89, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.305137, time: 1.0s\n",
      "beta: 0.9984012202447049\n",
      "beta: 0.9968024404894098\n",
      "beta: 0.9952036607341147\n",
      "beta: 0.9936048809788196\n",
      "beta: 0.9920061012235245\n",
      "beta: 0.9904073214682294\n",
      "beta: 0.9888085417129343\n",
      "beta: 0.9872097619576392\n",
      "beta: 0.9856109822023441\n",
      "epoch 10, training loss: 0.762094, time: 1.0s\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "epoch 20, training loss: 0.660350, time: 1.0s\n",
      "beta: 0.9840122024470495\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.60it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.21s/it]\n",
      "[I 2024-10-06 23:04:12,348] Trial 12 finished with value: 0.7929502369668247 and parameters: {'epochs': 20, 'rep_dim': 89, 'anom_ratio': 0.01598779755295056}. Best is trial 12 with value: 0.7929502369668247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=86, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=86, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=86, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=86, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.240027, time: 1.0s\n",
      "beta: 0.9986539158285056\n",
      "beta: 0.9973078316570112\n",
      "beta: 0.9959617474855168\n",
      "beta: 0.9946156633140224\n",
      "beta: 0.993269579142528\n",
      "beta: 0.9919234949710336\n",
      "beta: 0.9905774107995392\n",
      "beta: 0.9892313266280448\n",
      "beta: 0.9878852424565504\n",
      "epoch 10, training loss: 0.770260, time: 1.0s\n",
      "beta: 0.9878852424565504\n",
      "beta: 0.9878852424565504\n",
      "beta: 0.9878852424565504\n",
      "beta: 0.9878852424565504\n",
      "beta: 0.9878852424565504\n",
      "beta: 0.9878852424565504\n",
      "beta: 0.9878852424565504\n",
      "beta: 0.9878852424565504\n",
      "beta: 0.9878852424565504\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.63it/s]\n",
      "100%|██████████| 10/10 [00:21<00:00,  2.20s/it]\n",
      "[I 2024-10-06 23:04:55,125] Trial 13 finished with value: 0.7700086680150245 and parameters: {'epochs': 18, 'rep_dim': 86, 'anom_ratio': 0.012114757543449546}. Best is trial 12 with value: 0.7929502369668247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=86, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=86, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=86, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=86, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.240027, time: 1.0s\n",
      "beta: 0.9847637411466861\n",
      "beta: 0.9695274822933722\n",
      "beta: 0.9695274822933722\n",
      "beta: 0.9695274822933722\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.61it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.20s/it]\n",
      "[I 2024-10-06 23:05:24,124] Trial 14 finished with value: 0.2541678574830904 and parameters: {'epochs': 4, 'rep_dim': 86, 'anom_ratio': 0.03047251770662786}. Best is trial 12 with value: 0.7929502369668247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=120, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=120, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=120, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=120, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.218105, time: 1.0s\n",
      "beta: 0.9968074330506259\n",
      "beta: 0.9936148661012518\n",
      "beta: 0.9904222991518777\n",
      "beta: 0.9872297322025037\n",
      "beta: 0.9840371652531296\n",
      "beta: 0.9808445983037555\n",
      "beta: 0.9776520313543814\n",
      "beta: 0.9744594644050073\n",
      "beta: 0.9728631809303203\n",
      "epoch 10, training loss: 0.794312, time: 1.0s\n",
      "beta: 0.9728631809303203\n",
      "beta: 0.9728631809303203\n",
      "beta: 0.9728631809303203\n",
      "beta: 0.9728631809303203\n",
      "beta: 0.9728631809303203\n",
      "beta: 0.9728631809303203\n",
      "beta: 0.9728631809303203\n",
      "beta: 0.9728631809303203\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.61it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.23s/it]\n",
      "[I 2024-10-06 23:06:06,438] Trial 15 finished with value: 0.7832310838445807 and parameters: {'epochs': 17, 'rep_dim': 120, 'anom_ratio': 0.027136819069679678}. Best is trial 12 with value: 0.7929502369668247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=92, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=92, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=92, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=92, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.300288, time: 1.0s\n",
      "beta: 0.985507275060436\n",
      "beta: 0.971014550120872\n",
      "beta: 0.956521825181308\n",
      "beta: 0.9565218251813079\n",
      "beta: 0.9565218251813079\n",
      "beta: 0.9565218251813079\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.63it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.22s/it]\n",
      "[I 2024-10-06 23:06:37,497] Trial 16 finished with value: 0.26464315826017953 and parameters: {'epochs': 6, 'rep_dim': 92, 'anom_ratio': 0.04347817481869205}. Best is trial 12 with value: 0.7929502369668247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=76, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=76, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=76, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=76, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.289157, time: 1.0s\n",
      "beta: 0.9989625735769528\n",
      "beta: 0.9979251471539057\n",
      "beta: 0.9968877207308585\n",
      "beta: 0.9958502943078114\n",
      "beta: 0.9948128678847642\n",
      "beta: 0.993775441461717\n",
      "beta: 0.9927380150386699\n",
      "beta: 0.9917005886156227\n",
      "beta: 0.9906631621925756\n",
      "epoch 10, training loss: 0.779342, time: 1.0s\n",
      "beta: 0.9896257357695284\n",
      "beta: 0.9896257357695281\n",
      "beta: 0.9896257357695281\n",
      "beta: 0.9896257357695281\n",
      "beta: 0.9896257357695281\n",
      "beta: 0.9896257357695281\n",
      "beta: 0.9896257357695281\n",
      "beta: 0.9896257357695281\n",
      "beta: 0.9896257357695281\n",
      "beta: 0.9896257357695281\n",
      "epoch 20, training loss: 0.666561, time: 1.0s\n",
      "beta: 0.9896257357695281\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.63it/s]\n",
      "100%|██████████| 10/10 [00:21<00:00,  2.19s/it]\n",
      "[I 2024-10-06 23:07:22,244] Trial 17 finished with value: 0.7842501106031559 and parameters: {'epochs': 20, 'rep_dim': 76, 'anom_ratio': 0.010374264230471966}. Best is trial 12 with value: 0.7929502369668247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=118, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=118, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=118, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=118, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.285051, time: 1.0s\n",
      "beta: 0.9971706186559257\n",
      "beta: 0.9943412373118514\n",
      "beta: 0.9915118559677771\n",
      "beta: 0.9886824746237028\n",
      "beta: 0.9858530932796286\n",
      "beta: 0.9830237119355543\n",
      "beta: 0.98019433059148\n",
      "beta: 0.9787796399194426\n",
      "beta: 0.9787796399194426\n",
      "epoch 10, training loss: 0.789491, time: 1.0s\n",
      "beta: 0.9787796399194426\n",
      "beta: 0.9787796399194426\n",
      "beta: 0.9787796399194426\n",
      "beta: 0.9787796399194426\n",
      "beta: 0.9787796399194426\n",
      "beta: 0.9787796399194426\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.59it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.23s/it]\n",
      "[I 2024-10-06 23:08:02,432] Trial 18 finished with value: 0.7688740762208376 and parameters: {'epochs': 15, 'rep_dim': 118, 'anom_ratio': 0.021220360080557436}. Best is trial 12 with value: 0.7929502369668247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=93, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=93, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=93, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=93, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.320382, time: 1.0s\n",
      "beta: 0.9609436553060551\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.61it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.23s/it]\n",
      "[I 2024-10-06 23:08:28,634] Trial 19 finished with value: 0.22894242268921922 and parameters: {'epochs': 1, 'rep_dim': 93, 'anom_ratio': 0.039056344693944894}. Best is trial 12 with value: 0.7929502369668247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'epochs': 20, 'rep_dim': 89, 'anom_ratio': 0.01598779755295056}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    epochs = trial.suggest_int('epochs', 1, 20)\n",
    "    rep_dim = trial.suggest_int('rep_dim', 50, 150)\n",
    "    anom_ratio = trial.suggest_float('anom_ratio', 0.01, 0.1)\n",
    "\n",
    "    rca_model = RCA(epochs=epochs,\n",
    "                      rep_dim=rep_dim,\n",
    "                      anom_ratio=anom_ratio,\n",
    "                      random_state=42)\n",
    "\n",
    "    rca_model.fit(train_latent_features)\n",
    "    \n",
    "    val_predictions = rca_model.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 0, 1)\n",
    "    \n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=0, average='binary')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "875e4fcb-151e-43c4-a8eb-e16c02ebd63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=89, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=89, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=89, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=89, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.305137, time: 1.0s\n",
      "beta: 0.9984012202447049\n",
      "beta: 0.9968024404894098\n",
      "beta: 0.9952036607341147\n",
      "beta: 0.9936048809788196\n",
      "beta: 0.9920061012235245\n",
      "beta: 0.9904073214682294\n",
      "beta: 0.9888085417129343\n",
      "beta: 0.9872097619576392\n",
      "beta: 0.9856109822023441\n",
      "epoch 10, training loss: 0.762094, time: 1.0s\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "epoch 20, training loss: 0.660350, time: 1.0s\n",
      "beta: 0.9840122024470495\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.60it/s]\n",
      "100%|██████████| 10/10 [00:27<00:00,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9849\n",
      "Test Precision: 0.9965\n",
      "Test Recall: 0.9879\n",
      "Test F1 Score: 0.9922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_rca_model = RCA(epochs=best_params['epochs'],\n",
    "                      rep_dim=best_params['rep_dim'],\n",
    "                      anom_ratio=best_params['anom_ratio'],\n",
    "                      random_state=42)\n",
    "\n",
    "best_rca_model.fit(train_latent_features)\n",
    "test_predictions = best_rca_model.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f56a90-0ec5-4709-a6e0-ef43d3365978",
   "metadata": {},
   "source": [
    "# RDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "62292e86-08d3-4b31-92ed-d32b1ce9763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import RDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c499ff32-1b4e-43de-b567-d8f000a5a2ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 23:17:49,587] A new study created in memory with name: no-name-0f409735-4133-4385-ac72-055a082a7845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=63, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000019, time: 0.8s\n",
      "epoch 10, training loss: 0.000012, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 637.03it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 589.77it/s]\n",
      "[I 2024-10-06 23:18:01,555] Trial 0 finished with value: 0.8130859764612008 and parameters: {'epochs': 11, 'rep_dim': 63}. Best is trial 0 with value: 0.8130859764612008.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=93, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000017, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 636.59it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 590.67it/s]\n",
      "[I 2024-10-06 23:18:06,110] Trial 1 finished with value: 0.9363603861279943 and parameters: {'epochs': 2, 'rep_dim': 93}. Best is trial 1 with value: 0.9363603861279943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=82, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000018, time: 0.8s\n",
      "epoch 10, training loss: 0.000013, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 638.33it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 591.66it/s]\n",
      "[I 2024-10-06 23:18:22,974] Trial 2 finished with value: 0.920732813350263 and parameters: {'epochs': 17, 'rep_dim': 82}. Best is trial 1 with value: 0.9363603861279943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=82, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000018, time: 0.8s\n",
      "epoch 10, training loss: 0.000013, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 637.57it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 589.73it/s]\n",
      "[I 2024-10-06 23:18:34,894] Trial 3 finished with value: 0.9265740573696554 and parameters: {'epochs': 11, 'rep_dim': 82}. Best is trial 1 with value: 0.9363603861279943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=126, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000016, time: 0.8s\n",
      "epoch 10, training loss: 0.000015, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 639.99it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 593.20it/s]\n",
      "[I 2024-10-06 23:18:49,311] Trial 4 finished with value: 0.9373102339703518 and parameters: {'epochs': 14, 'rep_dim': 126}. Best is trial 4 with value: 0.9373102339703518.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=119, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000017, time: 0.8s\n",
      "epoch 10, training loss: 0.000014, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 636.05it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 588.57it/s]\n",
      "[I 2024-10-06 23:19:00,499] Trial 5 finished with value: 0.9373102339703518 and parameters: {'epochs': 10, 'rep_dim': 119}. Best is trial 4 with value: 0.9373102339703518.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=103, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000017, time: 0.9s\n",
      "epoch 10, training loss: 0.000014, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 640.03it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 593.85it/s]\n",
      "[I 2024-10-06 23:19:12,453] Trial 6 finished with value: 0.9376896982681664 and parameters: {'epochs': 11, 'rep_dim': 103}. Best is trial 6 with value: 0.9376896982681664.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=70, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000018, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 640.60it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 593.07it/s]\n",
      "[I 2024-10-06 23:19:22,719] Trial 7 finished with value: 0.8801054018445322 and parameters: {'epochs': 9, 'rep_dim': 70}. Best is trial 6 with value: 0.9376896982681664.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=112, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000016, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 637.95it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 593.26it/s]\n",
      "[I 2024-10-06 23:19:26,468] Trial 8 finished with value: 0.9439318665720369 and parameters: {'epochs': 1, 'rep_dim': 112}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=146, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000018, time: 0.8s\n",
      "epoch 10, training loss: 0.000016, time: 0.8s\n",
      "epoch 20, training loss: 0.000019, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 635.57it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 589.32it/s]\n",
      "[I 2024-10-06 23:19:45,889] Trial 9 finished with value: 0.940149625935162 and parameters: {'epochs': 20, 'rep_dim': 146}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=148, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000018, time: 0.9s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 544.96it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 512.47it/s]\n",
      "[I 2024-10-06 23:19:50,183] Trial 10 finished with value: 0.9362451567453328 and parameters: {'epochs': 1, 'rep_dim': 148}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=150, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000018, time: 0.9s\n",
      "epoch 10, training loss: 0.000016, time: 0.9s\n",
      "epoch 20, training loss: 0.000019, time: 0.9s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 637.68it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 590.84it/s]\n",
      "[I 2024-10-06 23:20:10,680] Trial 11 finished with value: 0.9376896982681664 and parameters: {'epochs': 20, 'rep_dim': 150}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=127, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000016, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 635.09it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 589.49it/s]\n",
      "[I 2024-10-06 23:20:17,750] Trial 12 finished with value: 0.9390156918687589 and parameters: {'epochs': 5, 'rep_dim': 127}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=109, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000017, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 635.74it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 590.09it/s]\n",
      "[I 2024-10-06 23:20:25,611] Trial 13 finished with value: 0.9348370927318296 and parameters: {'epochs': 6, 'rep_dim': 109}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=138, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000017, time: 0.8s\n",
      "epoch 10, training loss: 0.000015, time: 0.8s\n",
      "epoch 20, training loss: 0.000019, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 636.35it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 590.50it/s]\n",
      "[I 2024-10-06 23:20:45,042] Trial 14 finished with value: 0.9371204001429082 and parameters: {'epochs': 20, 'rep_dim': 138}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=114, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000015, time: 0.8s\n",
      "epoch 10, training loss: 0.000015, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 632.65it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 586.16it/s]\n",
      "[I 2024-10-06 23:21:00,347] Trial 15 finished with value: 0.9357896619567162 and parameters: {'epochs': 15, 'rep_dim': 114}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=136, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000016, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 632.57it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 586.43it/s]\n",
      "[I 2024-10-06 23:21:07,455] Trial 16 finished with value: 0.9359799713876967 and parameters: {'epochs': 5, 'rep_dim': 136}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=94, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000019, time: 0.8s\n",
      "epoch 10, training loss: 0.000014, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 639.90it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 592.59it/s]\n",
      "[I 2024-10-06 23:21:24,552] Trial 17 finished with value: 0.9285071132721052 and parameters: {'epochs': 17, 'rep_dim': 94}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=50, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000021, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 619.61it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 592.71it/s]\n",
      "[I 2024-10-06 23:21:33,222] Trial 18 finished with value: 0.762993762993763 and parameters: {'epochs': 7, 'rep_dim': 50}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=134, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000018, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 632.99it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 588.43it/s]\n",
      "[I 2024-10-06 23:21:38,653] Trial 19 finished with value: 0.940149625935162 and parameters: {'epochs': 3, 'rep_dim': 134}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'epochs': 1, 'rep_dim': 112}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    epochs = trial.suggest_int('epochs', 1, 20)\n",
    "    rep_dim = trial.suggest_int('rep_dim', 50, 150)\n",
    "\n",
    "    rdp_model = RDP(epochs=epochs,\n",
    "                      rep_dim=rep_dim,\n",
    "                      random_state=42)\n",
    "\n",
    "    rdp_model.fit(train_latent_features)\n",
    "    \n",
    "    val_predictions = rdp_model.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 0, 1)\n",
    "    \n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=0, average='binary')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9739df84-3e20-4aeb-bdcc-b3e51c9d9bb0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=112, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000016, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 634.31it/s]\n",
      "testing: 100%|██████████| 1841/1841 [00:03<00:00, 585.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9964\n",
      "Test Precision: 0.9963\n",
      "Test Recall: 0.9999\n",
      "Test F1 Score: 0.9981\n"
     ]
    }
   ],
   "source": [
    "best_rdp_model = RDP(epochs=best_params['epochs'],\n",
    "                      rep_dim=best_params['rep_dim'],\n",
    "                      random_state=42)\n",
    "\n",
    "best_rdp_model.fit(train_latent_features)\n",
    "test_predictions = best_rdp_model.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7427dba-e2f0-4781-9bd5-f915c8154c53",
   "metadata": {},
   "source": [
    "# DeepSVDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e7e030c-8b3f-4ab9-92fa-7f4b0a3f75ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import DeepSVDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bbbb4e19-009b-4592-b09e-c01f863ac2a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 23:14:56,567] A new study created in memory with name: no-name-1662ce95-527e-42bc-9244-08bccdbf11de\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=130, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.016776, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1424.48it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1427.19it/s]\n",
      "[I 2024-10-06 23:15:00,238] Trial 0 finished with value: 0.9454094292803971 and parameters: {'epochs': 7, 'rep_dim': 130}. Best is trial 0 with value: 0.9454094292803971.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=112, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.013780, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1319.99it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1325.42it/s]\n",
      "[I 2024-10-06 23:15:04,379] Trial 1 finished with value: 0.9412811387900356 and parameters: {'epochs': 8, 'rep_dim': 112}. Best is trial 0 with value: 0.9454094292803971.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=77, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.008463, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1328.59it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1327.39it/s]\n",
      "[I 2024-10-06 23:15:06,851] Trial 2 finished with value: 0.9418459896852214 and parameters: {'epochs': 3, 'rep_dim': 77}. Best is trial 0 with value: 0.9454094292803971.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=109, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.013614, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1430.00it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1328.19it/s]\n",
      "[I 2024-10-06 23:15:10,552] Trial 3 finished with value: 0.9437244807385052 and parameters: {'epochs': 7, 'rep_dim': 109}. Best is trial 0 with value: 0.9454094292803971.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=140, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.019233, time: 0.3s\n",
      "epoch 10, training loss: 0.000182, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1425.70it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1322.19it/s]\n",
      "[I 2024-10-06 23:15:15,483] Trial 4 finished with value: 0.9424102381798791 and parameters: {'epochs': 11, 'rep_dim': 140}. Best is trial 0 with value: 0.9454094292803971.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=119, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.016428, time: 0.3s\n",
      "epoch 10, training loss: 0.000153, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1423.68it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1322.98it/s]\n",
      "[I 2024-10-06 23:15:22,030] Trial 5 finished with value: 0.9459698848538529 and parameters: {'epochs': 16, 'rep_dim': 119}. Best is trial 5 with value: 0.9459698848538529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=139, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.019586, time: 0.3s\n",
      "epoch 10, training loss: 0.000157, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1310.59it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1321.94it/s]\n",
      "[I 2024-10-06 23:15:29,432] Trial 6 finished with value: 0.9405270655270656 and parameters: {'epochs': 18, 'rep_dim': 139}. Best is trial 5 with value: 0.9459698848538529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=54, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.006558, time: 0.3s\n",
      "epoch 10, training loss: 0.000083, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1322.91it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1327.63it/s]\n",
      "[I 2024-10-06 23:15:34,814] Trial 7 finished with value: 0.9416577730345073 and parameters: {'epochs': 12, 'rep_dim': 54}. Best is trial 5 with value: 0.9459698848538529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=147, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.020169, time: 0.3s\n",
      "epoch 10, training loss: 0.000211, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1427.78it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1325.38it/s]\n",
      "[I 2024-10-06 23:15:40,356] Trial 8 finished with value: 0.9439119630812921 and parameters: {'epochs': 13, 'rep_dim': 147}. Best is trial 5 with value: 0.9459698848538529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.016809, time: 0.3s\n",
      "epoch 10, training loss: 0.000154, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1315.49it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1325.52it/s]\n",
      "[I 2024-10-06 23:15:48,200] Trial 9 finished with value: 0.9483916578296218 and parameters: {'epochs': 19, 'rep_dim': 128}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=87, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.009505, time: 0.3s\n",
      "epoch 10, training loss: 0.000111, time: 0.3s\n",
      "epoch 20, training loss: 0.000083, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1419.25it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1324.89it/s]\n",
      "[I 2024-10-06 23:15:56,216] Trial 10 finished with value: 0.9388264669163545 and parameters: {'epochs': 20, 'rep_dim': 87}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=121, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.015052, time: 0.3s\n",
      "epoch 10, training loss: 0.000148, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1424.55it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1330.24it/s]\n",
      "[I 2024-10-06 23:16:02,967] Trial 11 finished with value: 0.9418459896852214 and parameters: {'epochs': 16, 'rep_dim': 121}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.011678, time: 0.3s\n",
      "epoch 10, training loss: 0.000110, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1225.02it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1137.49it/s]\n",
      "[I 2024-10-06 23:16:09,918] Trial 12 finished with value: 0.940149625935162 and parameters: {'epochs': 16, 'rep_dim': 100}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=124, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.015557, time: 0.4s\n",
      "epoch 10, training loss: 0.000153, time: 0.4s\n",
      "epoch 20, training loss: 0.000117, time: 0.4s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1138.34it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1142.81it/s]\n",
      "[I 2024-10-06 23:16:18,827] Trial 13 finished with value: 0.9403383793410508 and parameters: {'epochs': 20, 'rep_dim': 124}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=94, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.010652, time: 0.4s\n",
      "epoch 10, training loss: 0.000130, time: 0.4s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1231.57it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1140.64it/s]\n",
      "[I 2024-10-06 23:16:25,902] Trial 14 finished with value: 0.9412811387900356 and parameters: {'epochs': 15, 'rep_dim': 94}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=109, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.013614, time: 0.4s\n",
      "epoch 10, training loss: 0.000124, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1430.08it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1337.08it/s]\n",
      "[I 2024-10-06 23:16:33,161] Trial 15 finished with value: 0.9459698848538529 and parameters: {'epochs': 18, 'rep_dim': 109}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=132, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.017385, time: 0.3s\n",
      "epoch 10, training loss: 0.000158, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1431.39it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1328.52it/s]\n",
      "[I 2024-10-06 23:16:39,162] Trial 16 finished with value: 0.9420341394025604 and parameters: {'epochs': 14, 'rep_dim': 132}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=117, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.013745, time: 0.3s\n",
      "epoch 10, training loss: 0.000171, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1324.10it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1337.99it/s]\n",
      "[I 2024-10-06 23:16:46,515] Trial 17 finished with value: 0.9435369318181818 and parameters: {'epochs': 18, 'rep_dim': 117}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=75, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.008782, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1315.66it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1325.32it/s]\n",
      "[I 2024-10-06 23:16:48,355] Trial 18 finished with value: 0.9418459896852214 and parameters: {'epochs': 1, 'rep_dim': 75}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=150, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.018763, time: 0.3s\n",
      "epoch 10, training loss: 0.000197, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1419.63it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1323.42it/s]\n",
      "[I 2024-10-06 23:16:55,259] Trial 19 finished with value: 0.9457831325301205 and parameters: {'epochs': 17, 'rep_dim': 150}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'epochs': 19, 'rep_dim': 128}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    epochs = trial.suggest_int('epochs', 1, 20)\n",
    "    rep_dim = trial.suggest_int('rep_dim', 50, 150)\n",
    "\n",
    "    deepsvdd_model = DeepSVDD(epochs=epochs,\n",
    "                      rep_dim=rep_dim,\n",
    "                      random_state=42)\n",
    "\n",
    "    deepsvdd_model.fit(train_latent_features)\n",
    "    \n",
    "    val_predictions = deepsvdd_model.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 0, 1)\n",
    "    \n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=0, average='binary')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "08e6acf6-d090-43c3-94f3-b370315e9f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.016809, time: 0.3s\n",
      "epoch 10, training loss: 0.000154, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1437.26it/s]\n",
      "testing: 100%|██████████| 1841/1841 [00:01<00:00, 1320.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9967\n",
      "Test Precision: 0.9966\n",
      "Test Recall: 1.0000\n",
      "Test F1 Score: 0.9983\n"
     ]
    }
   ],
   "source": [
    "best_deepsvdd_model = DeepSVDD(epochs=best_params['epochs'],\n",
    "                      rep_dim=best_params['rep_dim'],\n",
    "                      random_state=42)\n",
    "\n",
    "best_deepsvdd_model.fit(train_latent_features)\n",
    "test_predictions = best_deepsvdd_model.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e832b6a-ca2d-49ef-b1c3-f4dcc5ebd0d6",
   "metadata": {},
   "source": [
    "# NeuTraL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14a6e0de-1625-4658-9934-aad14a20711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import NeuTraL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdf7bbeb-fc22-432c-afa6-4802479fef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "epoch  1, training loss: 0.136807, time: 20.6s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<deepod.models.tabular.neutral.NeuTraL at 0x7ff94824e790>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_model = NeuTraL(epochs=1)\n",
    "\n",
    "neutral_model.fit(train_latent_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95c2851d-5ff3-45a8-8ceb-bea3970bc495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9187\n",
      "Test Precision: 0.8755\n",
      "Test Recall: 0.9406\n",
      "Test F1 Score: 0.9069\n"
     ]
    }
   ],
   "source": [
    "test_predictions = neutral_model.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21fd19a-01c4-42e0-baa8-be816b51a7ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# GOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7c96efc0-3481-4ab6-8d1a-b7a6ad790f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import GOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a96b7cf7-422c-4f04-8cac-cf0780f7eab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-30 06:13:24,528] A new study created in memory with name: no-name-905e5c63-ea66-448a-b3f3-53f438593f73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "[W 2024-09-30 06:14:15,255] Trial 0 failed with parameters: {'epochs': 1, 'hidden_dim': 4, 'trans_dim': 38} because of the following error: RuntimeError('GET was unable to find an engine to execute this computation').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_833/704275057.py\", line 11, in objective\n",
      "    goad_model.fit(train_latent_features)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/deepod/core/base_model.py\", line 185, in fit\n",
      "    self._training()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/deepod/core/base_model.py\", line 339, in _training\n",
      "    loss.backward()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/_tensor.py\", line 525, in backward\n",
      "    )\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 267, in backward\n",
      "    grad,\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n",
      "RuntimeError: GET was unable to find an engine to execute this computation\n",
      "[W 2024-09-30 06:14:15,257] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 transformation done\n",
      "GoadNet(\n",
      "  (enc): ConvNet(\n",
      "    (net): Sequential(\n",
      "      (0): Conv1d(38, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (3): LeakyReLU(negative_slope=0.01)\n",
      "      (4): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (5): LeakyReLU(negative_slope=0.01)\n",
      "      (6): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (7): LeakyReLU(negative_slope=0.01)\n",
      "      (8): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (9): LeakyReLU(negative_slope=0.01)\n",
      "      (10): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (1): Conv1d(4, 256, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "GET was unable to find an engine to execute this computation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f1\n\u001b[1;32m     19\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[70], line 11\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      4\u001b[0m trans_dim \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrans_dim\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m      6\u001b[0m goad_model \u001b[38;5;241m=\u001b[39m GOAD(epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m      7\u001b[0m                   hidden_dim\u001b[38;5;241m=\u001b[39mhidden_dim,\n\u001b[1;32m      8\u001b[0m                   trans_dim\u001b[38;5;241m=\u001b[39mtrans_dim,\n\u001b[1;32m      9\u001b[0m                   random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mgoad_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_latent_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m val_predictions \u001b[38;5;241m=\u001b[39m goad_model\u001b[38;5;241m.\u001b[39mpredict(val_latent_features)\n\u001b[1;32m     14\u001b[0m val_true_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y_val \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/deepod/core/base_model.py:185\u001b[0m, in \u001b[0;36mBaseDeepAD.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_ensemble):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_prepare(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data,\n\u001b[1;32m    184\u001b[0m                                                                         y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_label)\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart Inference on the training data...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/deepod/core/base_model.py:339\u001b[0m, in \u001b[0;36mBaseDeepAD._training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_forward(batch_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 339\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    342\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39mregister_hook, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, hook)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot register a hook on a tensor that \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt require gradient\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 525\u001b[0m     )\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m overridable_args \u001b[38;5;241m=\u001b[39m t_outputs \u001b[38;5;241m+\u001b[39m t_inputs\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(overridable_args):\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m--> 267\u001b[0m         grad,\n\u001b[1;32m    268\u001b[0m         overridable_args,\n\u001b[1;32m    269\u001b[0m         t_outputs,\n\u001b[1;32m    270\u001b[0m         t_inputs,\n\u001b[1;32m    271\u001b[0m         grad_outputs\u001b[38;5;241m=\u001b[39mgrad_outputs,\n\u001b[1;32m    272\u001b[0m         retain_graph\u001b[38;5;241m=\u001b[39mretain_graph,\n\u001b[1;32m    273\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    274\u001b[0m         only_inputs\u001b[38;5;241m=\u001b[39monly_inputs,\n\u001b[1;32m    275\u001b[0m         allow_unused\u001b[38;5;241m=\u001b[39mallow_unused,\n\u001b[1;32m    276\u001b[0m         is_grads_batched\u001b[38;5;241m=\u001b[39mis_grads_batched,\n\u001b[1;32m    277\u001b[0m     )\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m only_inputs:\n\u001b[1;32m    280\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly_inputs argument is deprecated and is ignored now \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(defaults to True). To accumulate gradient for other \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts of the graph, please use torch.autograd.backward.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mRuntimeError\u001b[0m: GET was unable to find an engine to execute this computation"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    epochs = trial.suggest_int('epochs', 1, 20)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 2, 16)\n",
    "    trans_dim = trial.suggest_int('trans_dim', 16, 64)\n",
    "\n",
    "    goad_model = GOAD(epochs=epochs,\n",
    "                      hidden_dim=hidden_dim,\n",
    "                      trans_dim=trans_dim,\n",
    "                      random_state=42)\n",
    "\n",
    "    goad_model.fit(train_latent_features)\n",
    "    \n",
    "    val_predictions = goad_model.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 0, 1)\n",
    "    \n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=0, average='binary')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9c2f99-cdf0-4174-84b2-2c8faecebc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_goad_model = GOAD(epochs=best_params['epochs'],\n",
    "                        hidden_dim=best_params['hidden_dim'],\n",
    "                        trans_dim=best_params['trans_dim'],\n",
    "                        random_state=42)\n",
    "\n",
    "best_goad_model.fit(train_latent_features)\n",
    "test_predictions = best_goad_model.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3c1754-4945-46fb-9c59-61abfc593a44",
   "metadata": {},
   "source": [
    "# REPEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2081586b-94ae-4f5c-9f33-c2e2cbc7549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import REPEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22705f35-15d6-433b-8909-e57a9881f99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 20.007705, time: 438.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 3413/3413 [00:01<00:00, 2552.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<deepod.models.tabular.repen.REPEN at 0x7ff761092190>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repen_model = REPEN(epochs=1)\n",
    "\n",
    "repen_model.fit(train_latent_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f42d514b-767e-4e0b-b731-3052244acc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 1841/1841 [00:00<00:00, 2501.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8645\n",
      "Test Precision: 0.8587\n",
      "Test Recall: 0.8114\n",
      "Test F1 Score: 0.8344\n"
     ]
    }
   ],
   "source": [
    "test_predictions = repen_model.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dceafd-7141-4a3e-9ce4-3e3f0e1be157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
